{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gureBERT.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRIGPzfVoUlL",
        "colab_type": "text"
      },
      "source": [
        "#gureBERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvKEb2yhhFc-",
        "colab_type": "code",
        "outputId": "8a194482-b475-4eda-b73d-73cbb3a97f32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "# gureBERT\n",
        "\n",
        "!git clone --recursive  https://github.com/zmwebdev/gureBERT\n",
        "%cd gureBERT\n",
        "\n",
        "!pip install sentencepiece\n",
        "!install -d spModels\n",
        "# eu\n",
        "!python src/sentence-split.py --config eu.config.ini --do_lower_case \n",
        "!python src/train-sentencepiece.py --config eu.config.ini\n",
        "\n",
        "!head -n 100 spModels/eu.vocab\n",
        "\n",
        "# en-eu\n",
        "!python src/sentence-split.py --config en-eu.config.ini --do_lower_case \n",
        "!python src/train-sentencepiece.py --config en-eu.config.ini\n",
        "\n",
        "!head -n 100 spModels/en-eu.vocab\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gureBERT'...\n",
            "remote: Enumerating objects: 116, done.\u001b[K\n",
            "remote: Counting objects: 100% (116/116), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 225 (delta 59), reused 85 (delta 29), pack-reused 109\u001b[K\n",
            "Receiving objects: 100% (225/225), 7.02 MiB | 18.01 MiB/s, done.\n",
            "Resolving deltas: 100% (103/103), done.\n",
            "Submodule 'bert' (https://github.com/google-research/bert.git) registered for path 'bert'\n",
            "Cloning into '/content/gureBERT/bert'...\n",
            "remote: Enumerating objects: 329, done.        \n",
            "remote: Total 329 (delta 0), reused 0 (delta 0), pack-reused 329\n",
            "Receiving objects: 100% (329/329), 275.96 KiB | 3.78 MiB/s, done.\n",
            "Resolving deltas: 100% (181/181), done.\n",
            "Submodule path 'bert': checked out '0fce551b55caabcfba52c61e18f34b541aef186a'\n",
            "/content/gureBERT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-KNyUCP6Rtw",
        "colab_type": "code",
        "outputId": "08bafeb0-878f-425b-da1b-f1376395b2df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0713 05:13:49.337402 140654018004864 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ijk66GC0hIe3",
        "colab_type": "code",
        "outputId": "6169a132-de56-45a2-8141-29bc13189c8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# google bucket\n",
        "!gsutil cp -r gs://gurebert/gureBERT/spModels ."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://gurebert/gureBERT/spModels/en-eu.model...\n",
            "Copying gs://gurebert/gureBERT/spModels/en-eu.vocab...\n",
            "Copying gs://gurebert/gureBERT/spModels/eu.model...\n",
            "Copying gs://gurebert/gureBERT/spModels/eu.vocab...\n",
            "\\ [4 files][  2.9 MiB/  2.9 MiB]                                                \n",
            "Operation completed over 4 objects/2.9 MiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk8_HLFhpLYA",
        "colab_type": "code",
        "outputId": "216e2c27-4977-4249-af2a-71e4b9194888",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"src\")\n",
        "\n",
        "import tokenization_sentencepiece as tokenization\n",
        "\n",
        "tokenizer = tokenization.FullTokenizer(\n",
        "    model_file=\"spModels/eu.model\",\n",
        "    vocab_file=\"spModels/eu.vocab\",\n",
        "    do_lower_case=True)\n",
        "\n",
        "text1 = \"Nere kotxea aitonaren etxe alboan dago, bere kolorea gorria da. Nere baratzak 3 km² ditu. ni@ni.eus\"\n",
        "\n",
        "print(tokenizer.tokenize(text1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded a trained SentencePiece model.\n",
            "['▁nere', '▁ko', 'txea', '▁ait', 'onaren', '▁etxe', '▁alboan', '▁dago', ',', '▁bere', '▁kolorea', '▁gorria', '▁da', '.', '▁nere', '▁bar', 'atzak', '▁3', '▁km', '²', '▁ditu', '.', '▁ni', '@', 'ni', '.', 'eus']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9BPqkOUMHiz",
        "colab_type": "code",
        "outputId": "59c0086f-b865-421c-9089-5096b4b509f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "tokenizer_en_eu = tokenization.FullTokenizer(\n",
        "    model_file=\"spModels/en-eu.model\",\n",
        "    vocab_file=\"spModels/en-eu.vocab\",\n",
        "    do_lower_case=True)\n",
        "\n",
        "text1 = \"Nere kotxea aitonaren etxe alboan dago, bere kolorea gorria da.\"\n",
        "\n",
        "print(tokenizer_en_eu.tokenize(text1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded a trained SentencePiece model.\n",
            "['▁ne', 're', '▁ko', 'txea', '▁a', 'it', 'on', 'aren', '▁etxe', '▁', 'albo', 'an', '▁dago', ',', '▁bere', '▁kolore', 'a', '▁gorria', '▁da', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ojp8yYLUMUzt",
        "colab_type": "code",
        "outputId": "a0dd2d5f-19bd-4249-ffc8-d01abf8ac2d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "text1 = \"The Italian cities of Milan and Cortina d'Ampezzo are chosen as the joint hosts of the 2026 Winter Olympics and Winter Paralympics.\"\n",
        "\n",
        "print(\"EN-EU: {}\".format(tokenizer_en_eu.tokenize(text1)))\n",
        "print(\"EU: {}\".format(tokenizer.tokenize(text1)))\n",
        "\n",
        "print(\"EN-EU: {}\".format(len(tokenizer_en_eu.tokenize(text1))))\n",
        "print(\"EU: {}\".format(len(tokenizer.tokenize(text1))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EN-EU: ['▁the', '▁italian', '▁cities', '▁of', '▁milan', '▁and', '▁cort', 'ina', '▁d', \"'\", 'amp', 'e', 'zzo', '▁are', '▁chosen', '▁as', '▁the', '▁joint', '▁hosts', '▁of', '▁the', '▁20', '26', '▁winter', '▁olympics', '▁and', '▁winter', '▁para', 'lympic', 's', '.']\n",
            "EU: ['▁the', '▁italian', '▁cit', 'ies', '▁of', '▁milan', '▁and', '▁cor', 'tina', '▁d', \"'\", 'amp', 'ez', 'zo', '▁are', '▁ch', 'osen', '▁as', '▁the', '▁jo', 'int', '▁hos', 'ts', '▁of', '▁the', '▁20', '26', '▁winter', '▁olym', 'p', 'ics', '▁and', '▁winter', '▁paral', 'ym', 'p', 'ics', '.']\n",
            "EN-EU: 31\n",
            "EU: 38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNdhng5UqP6R",
        "colab_type": "code",
        "outputId": "cbd1a4cb-8d5a-4d95-a27b-8d8474f27610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "source": [
        "# Pre-Training\n",
        "# https://github.com/yoheikikuta/bert-japanese/blob/master/notebook/pretraining.ipynb\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "#Check TPU devices\n",
        "\n",
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0713 17:24:55.675337 140526703961984 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.51.131.226:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 6810479753173132532),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 9581148650088822417),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 14433261477188369500),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 10471305944331051035),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 290337485020010624),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 8844700230351949478),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 17633311837389007867),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 501559178114276546),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 7430056111459679944),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 13593346917957416754),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 11162654302255930259)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c76u8zhRog86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GS = 'gs://gurebert/gureBERT'\n",
        "  \n",
        "#!gsutil cp -r spModels $GS/\n",
        "#!gsutil cp -r corpus $GS/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFlsE3KI4Zcd",
        "colab_type": "text"
      },
      "source": [
        "## EU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlujbeOnmPC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 src/create_pretraining_data.py \\\n",
        "    --input_file=$GS/corpus/eu/2014wiki.eu.sent_splited \\\n",
        "    --output_file=$GS/pretraining.tf.data \\\n",
        "    --model_file=spModels/eu.model \\\n",
        "    --vocab_file=spModels/eu.vocab \\\n",
        "    --do_lower_case=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWLKYF-Hmkb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!install -d gureBERT\n",
        "\n",
        "!python src/run_pretraining.py \\\n",
        "  --config_file eu.config.ini \\\n",
        "  --input_file=$GS/pretraining.tf.data \\\n",
        "  --output_dir=$GS/eu.gureBERT/test \\\n",
        "  --do_train=True \\\n",
        "  --do_eval=True \\\n",
        "  --train_batch_size=256 \\\n",
        "  --max_seq_length=128 \\\n",
        "  --max_predictions_per_seq=20 \\\n",
        "  --num_train_steps=100 \\\n",
        "  --num_warmup_steps=10 \\\n",
        "  --save_checkpoints_steps=100 \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --use_tpu=True \\\n",
        "  --tpu_name={TPU_ADDRESS} \\\n",
        "#  --num_train_steps=1000000 \\\n",
        "\n",
        "# num_train_steps ? zenbatekoa?\n",
        "# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERgIisysvIh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pretraining jarraipena \n",
        "\n",
        "GS = 'gs://gurebert/gureBERT'\n",
        "\n",
        "!python src/run_pretraining.py \\\n",
        "  --config_file eu.config.ini \\\n",
        "  --input_file=$GS/pretraining.tf.data \\\n",
        "  --output_dir=$GS/eu.gureBERT/test \\\n",
        "  --do_train=True \\\n",
        "  --do_eval=True \\\n",
        "  --train_batch_size=64 \\\n",
        "  --max_seq_length=512 \\\n",
        "  --max_predictions_per_seq=20 \\\n",
        "  --num_train_steps=200 \\\n",
        "  --num_warmup_steps=10 \\\n",
        "  --save_checkpoints_steps=200 \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --use_tpu=True \\\n",
        "  --tpu_name={TPU_ADDRESS} \\\n",
        "  --init_checkpoint=$GS/eu.gureBERT/test \\\n",
        "#  --num_train_steps=1000000 \\\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAdbEYKv4P1m",
        "colab_type": "text"
      },
      "source": [
        "## EN-EU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbkJONUH77-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FILES = \"./corpus/en-eu/2014wiki.eu.sent_splited,./corpus/en-eu/2019wiki-10k.en.sent_splited\"\n",
        "\n",
        "!python3 src/create_pretraining_data.py \\\n",
        "    --input_file={FILES} \\\n",
        "    --output_file=$GS/pretraining-en_eu.tf.data \\\n",
        "    --model_file=spModels/en-eu.model \\\n",
        "    --vocab_file=spModels/en-eu.vocab \\\n",
        "    --do_lower_case=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p8b1EVZ79Ub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python src/run_pretraining.py \\\n",
        "  --config_file en-eu.config.ini \\\n",
        "  --input_file=$GS/pretraining-en_eu.tf.data \\\n",
        "  --output_dir=$GS/en-eu.gureBERT \\\n",
        "  --do_train=True \\\n",
        "  --do_eval=True \\\n",
        "  --train_batch_size=64 \\\n",
        "  --max_seq_length=512 \\\n",
        "  --max_predictions_per_seq=20 \\\n",
        "  --num_train_steps=20000 \\\n",
        "  --num_warmup_steps=10000 \\\n",
        "  --save_checkpoints_steps=10000 \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --use_tpu=True \\\n",
        "  --tpu_name={TPU_ADDRESS} \\\n",
        "  --init_checkpoint=$GS/en-eu.gureBERT/ \\\n",
        "  #--num_train_steps=1000000 \\\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne5xtoXYgOvM",
        "colab_type": "text"
      },
      "source": [
        "## SQuAD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxSQy-Gu47Bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pre training SQuAD\n",
        "\n",
        "# https://github.com/google-research/bert#squad-20\n",
        "\n",
        "#!git clone https://github.com/zmwebdev/bert.git\n",
        "#%cd bert\n",
        "\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
        "# evaluation script: download file from a url that returns a save dialog box : https://superuser.com/questions/795265/download-file-from-a-url-that-returns-a-save-dialog-box#795269\n",
        "!wget --content-disposition https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA0oUJsbBTaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sentenpiece tokenizer erabili behar da!!: src/run_squad.py\n",
        "\n",
        "!gsutil cp -r gs://gurebert/gureBERT/spModels .\n",
        "\n",
        " \n",
        "!python src/run_squad.py \\\n",
        "  --vocab_file=./spModels/en-eu.vocab \\\n",
        "  --model_file=./spModels/en-eu.model \\\n",
        "  --bert_config_file=bert_config.json \\\n",
        "  --do_lower_case=True \\\n",
        "  --do_train=True \\\n",
        "  --train_file=train-v2.0.json \\\n",
        "  --do_predict=True \\\n",
        "  --predict_file=dev-v2.0.json \\\n",
        "  --train_batch_size=24 \\\n",
        "  --learning_rate=3e-5 \\\n",
        "  --num_train_epochs=0.1 \\\n",
        "  --max_seq_length=384 \\\n",
        "  --doc_stride=128 \\\n",
        "  --output_dir=gs://gurebert/gureBERT/squad/ \\\n",
        "  --use_tpu=True \\\n",
        "  --tpu_name=$TPU_NAME \\\n",
        "  --version_2_with_negative=True \\\n",
        "  --init_checkpoint=gs://gurebert/gureBERT/squad/ \\\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lablZa6fsh51",
        "colab_type": "text"
      },
      "source": [
        "## wordpiece erabiliz\n",
        "\n",
        "- https://towardsdatascience.com/pre-training-bert-from-scratch-with-cloud-tpu-6e2f71028379\n",
        "- https://int-deepset-models-bert.s3.eu-central-1.amazonaws.com/pytorch/bert-base-german-cased-vocab.txt\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woWHbqZiI5sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# eu\n",
        "#!python src/sentence-split.py --config eu.config.ini --do_lower_case \n",
        "!python src/train-sentencepiece-wordpiece.py --config eu.config.ini\n",
        "\n",
        "!head -n 100 spModels/eu.vocab\n",
        "\n",
        "# en-eu\n",
        "!python src/sentence-split.py --config en-eu.config.ini --do_lower_case \n",
        "!python src/train-sentencepiece-wordpiece.py --config en-eu.config.ini\n",
        "\n",
        "!head -n 100 spModels/en-eu.vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e5XE43Q7D9i",
        "colab_type": "text"
      },
      "source": [
        "### EU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2XwxN-Z4a3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "def read_sentencepiece_vocab(filepath):\n",
        "  voc = []\n",
        "  with open(filepath, encoding='utf-8') as fi:\n",
        "    for line in fi:\n",
        "      voc.append(line.split(\"\\t\")[0])\n",
        "  # skip the first <unk> token\n",
        "  voc = voc[1:]\n",
        "  return voc\n",
        "\n",
        "snt_vocab = read_sentencepiece_vocab(\"{}.vocab\".format('./spModels/en-eu'))\n",
        "print(\"Learnt vocab size: {}\".format(len(snt_vocab)))\n",
        "print(\"Sample tokens: {}\".format(random.sample(snt_vocab, 10)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-YOATBGsg02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_sentencepiece_token(token):\n",
        "    if token.startswith(\"▁\"):\n",
        "        return token[1:]\n",
        "    else:\n",
        "        return \"##\" + token          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAx98r7zGZMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "\n",
        "bert_vocab = list(map(parse_sentencepiece_token, snt_vocab))\n",
        "\n",
        "VOC_FNAME = \"vocab.txt\"\n",
        "with open(VOC_FNAME, \"w\") as fo:\n",
        "  for token in bert_vocab:\n",
        "    fo.write(token+\"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYEtWr0D39Rf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import string\n",
        "\n",
        "#bert_vocab = list(map(parse_sentencepiece_token, snt_vocab))\n",
        "\n",
        "##########################\n",
        "#\n",
        "#   Falta diren sinbolo gehiketa modu automatikoan egin daiteke \n",
        "#   sentenpiece parametroak erabiliz:\n",
        "#   https://github.com/google/sentencepiece/blob/d4dd947fe71c4fa4ee24ad8297beee32887d8828/python/sentencepiece_python_module_example.ipynb\n",
        "#   https://towardsdatascience.com/pre-training-bert-from-scratch-with-cloud-tpu-6e2f71028379\n",
        "#\n",
        "##########################\n",
        "\n",
        "#ctrl_symbols = [\"[PAD]\",\"[UNK]\",\"[CLS]\",\"[SEP]\",\"[MASK]\"]\n",
        "## puntuazio sinboloak gehitu \n",
        "#ctrl_symbols_end = list(string.punctuation)\n",
        "##ctrl_symbols = [\"[UNK]\"]\n",
        "#bert_vocab = ctrl_symbols + bert_vocab + ctrl_symbols_end\n",
        "\n",
        "#bert_vocab = ctrl_symbols + bert_vocab\n",
        "\n",
        "## https://towardsdatascience.com/pre-training-bert-from-scratch-with-cloud-tpu-6e2f71028379\n",
        "## Additionally, we append some placeholder tokens to the vocabulary. \n",
        "## Those are useful if one wishes to update the pre-trained model with new, \n",
        "## task-specific tokens. In that case, the placeholder tokens are replaced with new real ones, \n",
        "## the pre-training data is re-generated, and the model is fine-tuned on new data.\n",
        "#\n",
        "# Nola egiten da re-generated?\n",
        "#\n",
        "#bert_vocab += [\"[UNUSED_{}]\".format(i) for i in range(32000 - len(bert_vocab))]\n",
        "\n",
        "#print(len(bert_vocab))\n",
        "\n",
        "#VOC_FNAME = \"vocab.txt\"\n",
        "#with open(VOC_FNAME, \"w\") as fo:\n",
        "#  for token in bert_vocab:\n",
        "#    fo.write(token+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLLaP8_04uY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bert import tokenization\n",
        "\n",
        "bert_tokenizer = tokenization.FullTokenizer(VOC_FNAME)\n",
        "#text1 = \"Nere kotxea aitonaren etxe alboan dago!, eta bere kolorea gorria da. ni@ni.eus erabili hitzhauezdaexixtitzen !~gg _*] \"\n",
        "#text1 = \"44.579.000 km²ko eremua eta 4.140.336.501 biztanle ditu\"\n",
        "#text1 = \"biologia izena grezierazko bi osagai erabiliz eratua da: βίος, bios, «bizitza»; eta -λογία, -logia, «azterketa».\"\n",
        "#text1 = \"手洗い\"\n",
        "text1 = \"ἀριστοτέλης meta+fisika km²\"\n",
        "print(\"num:{}, tokenak:{}\".format(len(bert_tokenizer.tokenize(text1)),bert_tokenizer.tokenize(text1)))\n",
        "print(\"num:{}, tokenak:{}\".format(len(tokenizer.tokenize(text1)),tokenizer.tokenize(text1)))\n",
        "\n",
        "# [UNK] ak agertzen dira wordpiece-ren kasuan token hori vocab-en ez badago, adibidez '~' karakterea. \n",
        "# Sentencepiece-ren kasuan, nahiz eta bere vocab-en ez egon ($ !cat spModels/en-eu.vocab | grep '~') tokenizatu egiten du\n",
        "# hau da, sentencepuecek 'dena' tokenizatzen du nahiz eta bere vocab-ean ez egon\n",
        "#\n",
        "# baina 'km²' corpusean agertzen da eta wordpiecek ez du tokenizatzen [UNK] bezala agertzen da. berdin 'ἄστρον' (ikusi beherago)\n",
        "# 'km²' ez da sentencepieceko en-eu.vocab-ean agertzen, baizik eta 'km' eta '2'. hau da: 'km²' -> ['km'] ['2'] tokenizatzen du eta BERT-ek ez\n",
        "# beraz kasu hauetan (karaktere arraroak? ...) 'eskuz' sartu beharko dira wordpiecen?\n",
        "# BERT base originaleko vocab.txt (edo germanBERT) aztertu eta ikusi bertan token hori dagoen..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXcKFgtJo73O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/google-research/bert/blob/master/create_pretraining_data.py\n",
        "# https://github.com/google-research/bert/blob/master/create_pretraining_data.py#L179\n",
        "\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "sys.path.append('bert')\n",
        "\n",
        "import create_pretraining_data\n",
        "import tokenization\n",
        "\n",
        "bert_tokenizer = tokenization.FullTokenizer(vocab_file=VOC_FNAME, do_lower_case=True)\n",
        "\n",
        "#all_documents = [[]]\n",
        "all_documents = []\n",
        "input_files = ['./corpus/eu/2014wiki.eu.sent_splited']\n",
        "for input_file in input_files:\n",
        "  with tf.gfile.GFile(input_file, \"r\") as reader:\n",
        "    while True:\n",
        "      line = tokenization.convert_to_unicode(reader.readline())\n",
        "      if not line:\n",
        "        break\n",
        "      line = line.strip()\n",
        "\n",
        "      # Empty lines are used as document delimiters\n",
        "      #if not line:\n",
        "      #  all_documents.append([])\n",
        "      tokens = bert_tokenizer.tokenize(line)\n",
        "      if tokens:\n",
        "        #all_documents[-1].append(tokens)\n",
        "        all_documents += tokens\n",
        "        #print(tokens)\n",
        "\n",
        "# Remove empty documents\n",
        "all_documents = [x for x in all_documents if x]\n",
        "#rng = random.Random(1234)\n",
        "#rng.shuffle(all_documents)\n",
        "\n",
        "print(\"token kop: {}\".format(len(all_documents)))\n",
        "print(\"[UNK] kop: {}\".format(all_documents.count('[UNK]')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qHdqxFz8rrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \n",
        "\n",
        "\n",
        "\n",
        "def bert_tokenize_corpus(filepath):\n",
        "  tokens = []\n",
        "  with open(filepath, encoding='utf-8') as fi:\n",
        "    for line in fi:\n",
        "      token_line = bert_tokenizer.tokenize(line)\n",
        "      tokens += token_line\n",
        "      if '[UNK]' in token_line:\n",
        "        print(\"testua: {}\".format(line))\n",
        "        print(\"tokenak: {}\".format(token_line))\n",
        "        print(\"---------------------------------------------------------\")\n",
        "        \n",
        "  return tokens\n",
        "\n",
        "def sentencepiece_tokenize_corpus(filepath):\n",
        "  tokens = []\n",
        "  with open(filepath, encoding='utf-8') as fi:\n",
        "    for line in fi:\n",
        "      tokens += tokenizer.tokenize(line)      \n",
        "  return tokens\n",
        "\n",
        "\n",
        "bert_tokens = bert_tokenize_corpus(\"./corpus/eu/2014wiki.eu.sent_splited\")\n",
        "sentencepiece_tokens = sentencepiece_tokenize_corpus(\"./corpus/eu/2014wiki.eu.sent_splited\")\n",
        "\n",
        "print(\"wordpiece tokens: {}\".format(len(bert_tokens)))\n",
        "print(\"sentencepiece tokens: {}\".format(len(sentencepiece_tokens)))\n",
        "\n",
        "print(\"Wordpiece [UNK] kop: {}\".format(bert_tokens.count('[UNK]')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn54GJq95Uf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python bert/create_pretraining_data.py \\\n",
        "  --input_file=$GS/corpus/eu/2014wiki.eu.sent_splited \\\n",
        "  --output_file=$GS/wordpiece/pretraining.tf.data \\\n",
        "  --vocab_file=vocab.txt \\\n",
        "  --do_lower_case=True \\\n",
        "  --max_seq_length=512 \\\n",
        "  --max_predictions_per_seq=20 \\\n",
        "  --masked_lm_prob=0.15 \\\n",
        "  --random_seed=666 \\\n",
        "  --do_whole_word_mask=True \\\n",
        "  #--dupe_factor=5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvMUE9sT6P1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "!python src/run_pretraining.py \\\n",
        "  --config_file eu.congif.ini \\\n",
        "  --input_file=$GS/pretraining.tf.data \\\n",
        "  --output_dir=$GS/eu.gureBERT \\\n",
        "  --do_train=True \\\n",
        "  --do_eval=True \\\n",
        "  --train_batch_size=64 \\\n",
        "  --max_seq_length=512 \\\n",
        "  --max_predictions_per_seq=20 \\\n",
        "  --num_train_steps=1000000 \\\n",
        "  --num_warmup_steps=10000 \\\n",
        "  --save_checkpoints_steps=10000 \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --use_tpu=True \\\n",
        "  --tpu_name={TPU_ADDRESS} \\\n",
        "'''\n",
        "\n",
        "!python bert/run_pretraining.py \\\n",
        "  --input_file=$GS/wordpiece/pretraining.tf.data \\ \\\n",
        "  --output_dir=$GS/wordpiece/model \\\n",
        "  --do_train=True \\\n",
        "  --do_eval=True \\\n",
        "  --bert_config_file=bert_config.json \\\n",
        "  --train_batch_size=64 \\\n",
        "  --max_seq_length=512 \\\n",
        "  --max_predictions_per_seq=20 \\\n",
        "  --num_train_steps=10000 \\\n",
        "  --num_warmup_steps=10000 \\\n",
        "  --save_checkpoints_steps=10000 \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --use_tpu=True \\\n",
        "  --tpu_name={TPU_ADDRESS} \\\n",
        "  #--num_train_steps=1000000 \\\n",
        "  #--init_checkpoint=$GS/wordpiece/model \\"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNV42_z-O92_",
        "colab_type": "text"
      },
      "source": [
        "### EN-EU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k-kNc1NmPg55",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "def read_sentencepiece_vocab(filepath):\n",
        "  voc = []\n",
        "  with open(filepath, encoding='utf-8') as fi:\n",
        "    for line in fi:\n",
        "      voc.append(line.split(\"\\t\")[0])\n",
        "  # skip the first <unk> token\n",
        "  voc = voc[1:]\n",
        "  return voc\n",
        "\n",
        "snt_vocab = read_sentencepiece_vocab(\"{}.vocab\".format('./spModels/en-eu'))\n",
        "print(\"Learnt vocab size: {}\".format(len(snt_vocab)))\n",
        "print(\"Sample tokens: {}\".format(random.sample(snt_vocab, 10)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IMHIP2dDPg7M",
        "colab": {}
      },
      "source": [
        "# hau errepasatu. adibidez @ ez dut ondo egiten... [UNK] agertzen da...\n",
        "# adibidez, \n",
        "\n",
        "#import string\n",
        "#def parse_sentencepiece_token(token):\n",
        "#    if token.startswith(\"▁\"):\n",
        "#        return token[1:]\n",
        "#    else:\n",
        "#        if token in string.punctuation:\n",
        "#            return token\n",
        "#        else:\n",
        "#            return \"##\" + token\n",
        "          \n",
        "\n",
        "def parse_sentencepiece_token(token):\n",
        "    if token.startswith(\"▁\"):\n",
        "        return token[1:]\n",
        "    else:\n",
        "        return \"##\" + token          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TYrllb6wPg7f",
        "colab": {}
      },
      "source": [
        "import string\n",
        "\n",
        "bert_vocab = list(map(parse_sentencepiece_token, snt_vocab))\n",
        "\n",
        "ctrl_symbols = [\"[PAD]\",\"[UNK]\",\"[CLS]\",\"[SEP]\",\"[MASK]\"]\n",
        "# puntuazio sinboloak gehitu \n",
        "ctrl_symbols_end = list(string.punctuation)\n",
        "#ctrl_symbols = [\"[UNK]\"]\n",
        "bert_vocab = ctrl_symbols + bert_vocab + ctrl_symbols_end\n",
        "\n",
        "#bert_vocab += [\"[UNUSED_{}]\".format(i) for i in range(32000 - len(bert_vocab))]\n",
        "print(len(bert_vocab))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RQVCJ3izPg72",
        "colab": {}
      },
      "source": [
        "VOC_FNAME = \"vocab-en_eu.txt\"\n",
        "with open(VOC_FNAME, \"w\") as fo:\n",
        "  for token in bert_vocab:\n",
        "    fo.write(token+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lm-A4Er3Pg8D",
        "colab": {}
      },
      "source": [
        "from bert import tokenization\n",
        "\n",
        "bert_tokenizer = tokenization.FullTokenizer(VOC_FNAME)\n",
        "print(bert_tokenizer.tokenize(\"Nere kotxea aitonaren etxe alboan dago!, eta bere kolorea gorria da. ni@ni.eus erabili \"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q0P25Z_LPg8W",
        "colab": {}
      },
      "source": [
        "FILES = \"./corpus/en-eu/2014wiki.eu.sent_splited,./corpus/en-eu/2019wiki-10k.en.sent_splited\"\n",
        "\n",
        "!python bert/create_pretraining_data.py \\\n",
        "  --input_file={FILES} \\\n",
        "  --output_file=$GS/wordpiece/pretraining-en_eu.tf.data \\\n",
        "  --vocab_file=vocab-en_eu.txt \\\n",
        "  --do_lower_case=True \\\n",
        "  --max_seq_length=512 \\\n",
        "  --max_predictions_per_seq=20 \\\n",
        "  --masked_lm_prob=0.15 \\\n",
        "  --random_seed=666 \\\n",
        "  --do_whole_word_mask=True \\\n",
        "  #--dupe_factor=5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o1hyibNBPg8o",
        "colab": {}
      },
      "source": [
        "'''\n",
        "!python src/run_pretraining.py \\\n",
        "  --config_file eu.congif.ini \\\n",
        "  --input_file=$GS/pretraining.tf.data \\\n",
        "  --output_dir=$GS/eu.gureBERT \\\n",
        "  --do_train=True \\\n",
        "  --do_eval=True \\\n",
        "  --train_batch_size=64 \\\n",
        "  --max_seq_length=512 \\\n",
        "  --max_predictions_per_seq=20 \\\n",
        "  --num_train_steps=1000000 \\\n",
        "  --num_warmup_steps=10000 \\\n",
        "  --save_checkpoints_steps=10000 \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --use_tpu=True \\\n",
        "  --tpu_name={TPU_ADDRESS} \\\n",
        "'''\n",
        "\n",
        "!python bert/run_pretraining.py \\\n",
        "  --input_file=$GS/wordpiece/pretraining-en_eu.tf.data \\ \\\n",
        "  --output_dir=$GS/wordpiece/model-en_eu \\\n",
        "  --do_train=True \\\n",
        "  --do_eval=True \\\n",
        "  --bert_config_file=bert_config.json \\\n",
        "  --train_batch_size=64 \\\n",
        "  --max_seq_length=512 \\\n",
        "  --max_predictions_per_seq=20 \\\n",
        "  --num_train_steps=20000 \\\n",
        "  --num_warmup_steps=10000 \\\n",
        "  --save_checkpoints_steps=10000 \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --use_tpu=True \\\n",
        "  --tpu_name={TPU_ADDRESS} \\\n",
        "  --init_checkpoint=$GS/wordpiece/model-en_eu/ \\\n",
        "  #--num_train_steps=1000000 \\\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zAbTlosgZiP",
        "colab_type": "text"
      },
      "source": [
        "### SQuAD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrHSiJmsa_up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data English da!! baino kodea badabil \n",
        "\n",
        "!python bert/run_squad.py \\\n",
        "  --vocab_file=vocab-en_eu.txt \\\n",
        "  --bert_config_file=bert_config.json \\\n",
        "  --do_lower_case=True \\\n",
        "  --do_train=True \\\n",
        "  --train_file=train-v2.0.json \\\n",
        "  --do_predict=True \\\n",
        "  --predict_file=dev-v2.0.json \\\n",
        "  --train_batch_size=24 \\\n",
        "  --learning_rate=3e-5 \\\n",
        "  --num_train_epochs=0.1 \\\n",
        "  --max_seq_length=384 \\\n",
        "  --doc_stride=128 \\\n",
        "  --output_dir=gs://gurebert/gureBERT/wordpiece/squad/ \\\n",
        "  --use_tpu=True \\\n",
        "  --tpu_name=$TPU_NAME \\\n",
        "  --version_2_with_negative=True \\\n",
        "  --init_checkpoint=gs://gurebert/gureBERT/wordpiece/model-en_eu/ \\"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6Pc8ihcPDb0",
        "colab_type": "text"
      },
      "source": [
        "# gureBERT EN-EU Sorkuntza\n",
        "\n",
        "Ideia honakoa da: colab erabiliz BERT EN-EU entrenatzea. Ikusi:\n",
        "\n",
        "- gureBERT japanese begiratu wikipediatik corpusaren prozesamendua\n",
        "- gureBERT wordpiece nola egin begiratu\n",
        "- https://github.com/zmwebdev/chatbot/issues/22#issuecomment-507390915"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2TqPuzv88I2",
        "colab_type": "text"
      },
      "source": [
        "## Euskarazko vocab.txt sortu\n",
        "\n",
        "Euskarazko vocab.txt sortu euskarazko wikiedia osoa hartuta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYbMfb3H85IF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "\n",
        "!cp eu.config.ini config.ini\n",
        "\n",
        "!mkdir data\n",
        "!python src/data-download-and-extract.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7DSWzgnJvCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!bash src/file-preprocessing.sh\n",
        "!python src/sentence-split.py --config eu.config.ini --do_lower_case \n",
        "\n",
        "####\n",
        "!rm -Rf corpus/eu\n",
        "!gsutil -m cp -r gs://gurebert/gureBERT/corpus/eu/[A-Z][A-Z] corpus/eu\n",
        "####\n",
        "\n",
        "!pip install sentencepiece\n",
        "#!python src/train-sentencepiece-wordpiece.py --config eu.config.ini\n",
        "!python src/train-sentencepiece-wordpiece.py --config eu.config.ini --tokenized True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8f9w3ePe8xm",
        "colab_type": "code",
        "outputId": "7206dcd4-4d2e-44ff-a9c3-ca98a1eaefa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# gs-ra kopiatu\n",
        "\n",
        "!gsutil cp -r spModels/* gs://gurebert/gureBERT/spModels\n",
        "!gsutil cp -r corpus/eu/* gs://gurebert/gureBERT/\n",
        "  \n",
        "# gs-tik kopiatu\n",
        "!gsutil cp -r gs://gurebert/gureBERT/spModels .\n",
        "!gsutil -m cp -r gs://gurebert/gureBERT/corpus/eu/[A-Z][A-Z] corpus/eu  # begiratu ea corpus/eu -n gordetzen dituen\n",
        "#!gsutil cp -r gs://gurebert/gureBERT/corpus/eu corpus/eu\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://spModels/eu.model [Content-Type=application/octet-stream]...\n",
            "Copying file://spModels/eu.vocab [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 2 objects/938.9 KiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWAk_pXQY6BT",
        "colab_type": "code",
        "outputId": "6a1c0a87-1099-4def-b9d9-dfc6aa6c8faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# sentencepiece2wordpiece\n",
        "\n",
        "import random\n",
        "\n",
        "def read_sentencepiece_vocab(filepath):\n",
        "  voc = []\n",
        "  with open(filepath, encoding='utf-8') as fi:\n",
        "    for line in fi:\n",
        "      voc.append(line.split(\"\\t\")[0])\n",
        "  # skip the first <unk> token\n",
        "  voc = voc[1:]\n",
        "  return voc\n",
        "\n",
        "snt_vocab = read_sentencepiece_vocab(\"{}.vocab\".format('./spModels/eu'))\n",
        "print(\"Learnt vocab size: {}\".format(len(snt_vocab)))\n",
        "print(\"Sample tokens: {}\".format(random.sample(snt_vocab, 10)))\n",
        "\n",
        "\n",
        "#\n",
        "def parse_sentencepiece_token(token):\n",
        "    if token.startswith(\"▁\"):\n",
        "        return token[1:]\n",
        "    else:\n",
        "        return \"##\" + token\n",
        "      \n",
        "\n",
        "\n",
        "##########################\n",
        "#\n",
        "#   Falta diren sinbolo gehiketa modu automatikoan egin daiteke \n",
        "#   sentenpiece parametroak erabiliz:\n",
        "#   https://github.com/google/sentencepiece/blob/d4dd947fe71c4fa4ee24ad8297beee32887d8828/python/sentencepiece_python_module_example.ipynb\n",
        "#   https://towardsdatascience.com/pre-training-bert-from-scratch-with-cloud-tpu-6e2f71028379\n",
        "#\n",
        "##########################\n",
        "\n",
        "\n",
        "gure_bert_vocab = list(map(parse_sentencepiece_token, snt_vocab))\n",
        "\n",
        "#\n",
        "ctrl_symbols = [\"[PAD]\",\"[UNK]\",\"[CLS]\",\"[SEP]\",\"[MASK]\"]  # hau automatikoki egin daiteke begiratu goiko url-a\n",
        "#ctrl_symbols = [\"[PAD]\",\"[CLS]\",\"[SEP]\",\"[MASK]\"]  # hau automatikoki egin daiteke begiratu goiko url-a\n",
        "\n",
        "import string\n",
        "punctuation_list = list(string.punctuation)\n",
        "\n",
        "bert_vocab = ctrl_symbols + gure_bert_vocab + punctuation_list\n",
        "\n",
        "unused_tokens = [\"[UNUSED_{}]\".format(i) for i in range(32000 - len(bert_vocab))]\n",
        "\n",
        "bert_vocab = ctrl_symbols + unused_tokens + gure_bert_vocab + punctuation_list\n",
        "\n",
        "'''\n",
        "################################\n",
        "# BERT base uncaset vocab-etik (model-bert-base-uncased/vocab.bert.base.txt)\n",
        "# lehenengo tokenak 'the' tokenetik hasierara\n",
        "x = !cat model-bert-base-uncased/vocab.bert.base.txt| grep -n '^the$' | cut -d: -f1\n",
        "n = int(x[0])-1\n",
        "bert_tokens = !cat model-bert-base-uncased/vocab.bert.base.txt| head -n {n} \n",
        "# azkenengo tokenak 'necessitated' tik bukaera\n",
        "x = !cat model-bert-base-uncased/vocab.bert.base.txt| grep -n '^necessitated$' | cut -d: -f1\n",
        "n = int(x[0])+1\n",
        "nn = !cat model-bert-base-uncased/vocab.bert.base.txt| wc -l\n",
        "n = int(nn[0])-n+1\n",
        "bert_tokens_azken = !cat model-bert-base-uncased/vocab.bert.base.txt| tail -n {n} \n",
        "  \n",
        "# remove [unusedX]\n",
        "bert_tokens = [ elem for elem in bert_tokens if not elem.startswith( '[unused' )]\n",
        "bert_control_tokens = bert_tokens[0:5]\n",
        "bert_tokens = bert_tokens[5:-1]\n",
        "\n",
        "#print(\"BERT control tokens: {}\".format(bert_control_tokens))\n",
        "#print(\"BERT tokens: {}\".format(bert_tokens))\n",
        "#\n",
        "\n",
        "# ez daudenak aukeratu\n",
        "bert_tokens = [ elem for elem in bert_tokens if not elem in gure_bert_vocab]\n",
        "bert_tokens_azken = [ elem for elem in bert_tokens_azken if not elem in gure_bert_vocab]\n",
        "\n",
        "\n",
        "# UNUSED_X ak sortzen dira etorkizunean token berriak gehitu behar badira\n",
        "bert_vocab_tmp = bert_control_tokens + bert_tokens + gure_bert_vocab + bert_tokens_azken\n",
        "unused_tokens += [\"[UNUSED_{}]\".format(i) for i in range(32000 - len(bert_vocab_tmp))]\n",
        "\n",
        "# dena batu\n",
        "bert_vocab = bert_control_tokens + unused_tokens + bert_tokens + gure_bert_vocab + bert_tokens_azken\n",
        "#################################\n",
        "'''\n",
        "\n",
        "VOC_FNAME = \"wpModels/vocab.eu.txt\"\n",
        "with open(VOC_FNAME, \"w\", encoding='utf-8') as fo:\n",
        "  for token in bert_vocab:\n",
        "    fo.write(token+\"\\n\")\n",
        "    \n",
        "#\n",
        "#  SORTZEN DEN FITXATEGIAN txt KARAKTERA 'ARRAROAK'(beriratu amaierakoak) AGERTZEN DIRA BERT base-rekin KONPARATU!! \n",
        "#\n",
        "\n",
        "#\n",
        "#!mv vocab.eu.txt wpModels\n",
        "!gsutil cp -r wpModels/vocab.eu.txt gs://gurebert/gureBERT/wpModels\n",
        "  \n",
        "#!gsutil cp -r gs://gurebert/gureBERT/wpModels/vocab.eu.txt .\n",
        "\n",
        "#!head -n 100 wpModels/vocab.eu.txt\n",
        "#!tail -n 100 wpModels/vocab.eu.txt\n",
        "\n",
        "#!cat wpModels/vocab.eu.txt | grep -n \\\\##²\n",
        "\n",
        "print(\"Sample tokens: {}\".format(random.sample(bert_vocab, 10)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learnt vocab size: 29999\n",
            "Sample tokens: ['モ', '▁doktoreak', '▁diputatu', '▁akusazio', '▁olerki', '▁1876', 'gau', '▁bakoitzeko', '▁ramirez', 'र']\n",
            "Copying file://wpModels/vocab.eu.txt [Content-Type=text/plain]...\n",
            "/ [1 files][246.4 KiB/246.4 KiB]                                                \n",
            "Operation completed over 1 objects/246.4 KiB.                                    \n",
            "Sample tokens: ['##โ', 'esleitze', '##capelle', 'gehiagoko', 'kashiwa', '##隊', 'mugak', 'eraztun', 'molde', 'kantauriar']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXqwyRiOMZbp",
        "colab_type": "code",
        "outputId": "d89ad3ff-50ef-4fa8-88ea-c3d8058a43c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from bert import tokenization\n",
        "\n",
        "VOC_FNAME = \"wpModels/vocab.eu.txt\"\n",
        "\n",
        "bert_tokenizer = tokenization.FullTokenizer(VOC_FNAME)\n",
        "text1 = \"Nere kotxea aitonaren etxe alboan dago!, eta bere kolorea gorria da. ni@ni.eus erabili hitzhauezdaexixtitzen !~gg _*] \"\n",
        "#text1 = \"44.579.000 km²ko eremua eta 4.140.336.501 biztanle ditu\"\n",
        "#text1 = \"k m²-ko km²-ko bainnn \"\n",
        "#text1 = \"biologia izena grezierazko bi osagai erabiliz eratua da: βίος, bios, «bizitza»; eta -λογία, -logia, «azterketa».\"\n",
        "#text1 = \"手洗い\"\n",
        "#text1 = \"kaña bat nahi dut\"\n",
        "#text1 = \"ἀριστοτέλης meta+fisika km²\"\n",
        "print(\"num:{}, tokenak:{}\".format(len(bert_tokenizer.tokenize(text1)),bert_tokenizer.tokenize(text1)))\n",
        "\n",
        "\n",
        "# [UNK] ak agertzen dira wordpiece-ren kasuan token hori vocab-en ez badago, adibidez '~' karakterea. \n",
        "# Sentencepiece-ren kasuan, nahiz eta bere vocab-en ez egon ($ !cat spModels/en-eu.vocab | grep '~') tokenizatu egiten du\n",
        "# hau da, sentencepuecek 'dena' tokenizatzen du nahiz eta bere vocab-ean ez egon\n",
        "#\n",
        "# baina 'km²' corpusean agertzen da eta wordpiecek ez du tokenizatzen [UNK] bezala agertzen da. berdin 'ἄστρον' (ikusi beherago)\n",
        "# 'km²' ez da sentencepieceko en-eu.vocab-ean agertzen, baizik eta 'km' eta '2'. hau da: 'km²' -> ['km'] ['2'] tokenizatzen du eta BERT-ek ez\n",
        "# beraz kasu hauetan (karaktere arraroak? ...) 'eskuz' sartu beharko dira wordpiecen? ikusi hurrengo 'code cell'...\n",
        "# (BERT base originaleko vocab.txt (edo germanBERT) aztertu eta ikusi bertan token hori dagoen...)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num:39, tokenak:['nere', 'kotxe', '##a', 'aitona', '##ren', 'etxe', 'albo', '##an', 'dago', '!', ',', 'eta', 'bere', 'kolorea', 'gorria', 'da', '.', 'ni', '@', 'ni', '.', 'eu', '##s', 'erabili', 'hitz', '##hau', '##ez', '##dae', '##xi', '##x', '##ti', '##tzen', '!', '~', 'g', '##g', '_', '*', ']']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv6bSdK-c6gI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# corpus guztian [UNK] -ak aurkitu eta ikusi zein hitz diren. Hauek [UNUSED] horietak jarri (edo amaieran gehitu eta gero jarri [UNUSED]-ak)\n",
        "# hurrengo \n",
        "\n",
        "def find_unk_sentences(filepath):\n",
        "  unk_lines = []\n",
        "  tokens = []\n",
        "  with open(filepath, encoding='utf-8') as fi:\n",
        "    for line in fi:\n",
        "      token_line = bert_tokenizer.tokenize(line)\n",
        "      tokens += token_line\n",
        "      if '[UNK]' in token_line:\n",
        "        print(\"testua: {}\".format(line))\n",
        "        print(\"tokenak: {}\".format(token_line))\n",
        "        print(\"---------------------------------------------------------\")\n",
        "        unk_lines.append(line)\n",
        "  return unk_lines\n",
        "\n",
        "\n",
        "def find_unk_word(unk_lines):\n",
        "  unk_words = []\n",
        "  for line in unk_lines:\n",
        "    for w in line:\n",
        "      token = bert_tokenizer.tokenize(w)\n",
        "      if '[UNK]' in token:\n",
        "        unk_words.append(w)\n",
        "  return set(unk_lines)\n",
        "\n",
        "\n",
        "import glob\n",
        "\n",
        "def _get_text_file(text_dir=''):\n",
        "    file_list = glob.glob(f'{text_dir}/*/*.sent_splited')\n",
        "    files = \",\".join(file_list)\n",
        "    return files\n",
        "\n",
        "files = _get_text_file('./corpus/eu/')\n",
        "#### HAU KENDU!! proba bat da!!\n",
        "#files = 'corpus/eu/AA/wiki_00.sent_splited'\n",
        "\n",
        "\n",
        "#unk_words = []\n",
        "unk_sentences = []\n",
        "for fs in files.split(\",\"):\n",
        "  #tmp = find_unk_sentences(fs)\n",
        "  #tmp2 = find_unk_word(tmp)\n",
        "  #unk_words = unk_words.append(find_unk_word(find_unk_sentences(fs)))\n",
        "  unk_sentences.append(find_unk_sentences(fs))\n",
        "\n",
        "print(\"Wordpiece [UNK] sentences len: {}\".format(len(unk_sentences)))\n",
        "#print(\"Wordpiece [UNK] words: {}\".format(unk_words))\n",
        " \n",
        "\n",
        "#hitza zein den aurkite eta zerrenda bat egin. gero vocab-ean sartu\n",
        "#print(\"wordpiece tokens: {}\".format(len(bert_tokens)))\n",
        "#print(\"sentencepiece tokens: {}\".format(len(sentencepiece_tokens)))\n",
        "\n",
        "print(tmp2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4-i8oI58JrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DtX-Fxa-qns",
        "colab_type": "text"
      },
      "source": [
        "## pre-train\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VFrRMJ38ty2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating data for pretraining\n",
        "#Create .tfrecord files for pretraining. For longer sentence data, replace the value of max_seq_length with 512.\n",
        "\n",
        "#!cat src/creating_data_for_pretraining.sh\n",
        "#!bash src/creating_data_for_pretraining.sh BERT-ena erabili!!!!\n",
        "\n",
        "\n",
        "# The max_predictions_per_seq is the maximum number of masked LM predictions per sequence. \n",
        "# You should set this to around max_seq_length * masked_lm_prob \n",
        "# (the script doesn't do that automatically because the exact value needs to be passed to both scripts).\n",
        "\n",
        "\n",
        "MAX_SEQ_LEN = 128\n",
        "#MAX_SEQ_LEN = 512\n",
        "MASKED_LM_PROB = 0.15\n",
        "MAX_PREDICTIONS_PER_SEQ = round(MAX_SEQ_LEN * MASKED_LM_PROB)\n",
        "\n",
        "\n",
        "#input_files_list = glob.glob(f'corpus/eu/*/*.sent_splited')\n",
        "#input_files_list = glob.glob(f'gs://gurebert/gureBERT/corpus/*/*.sent_splited')\n",
        "input_files_list = !gsutil ls gs://gurebert/gureBERT/corpus/eu/*/*.sent_splited\n",
        "#input_files_list = ['gs://gurebert/gureBERT/corpus/AA/wiki_00.sent_splited']\n",
        "\n",
        "for file in input_files_list:\n",
        "  out_file = file + '.tfrecord'\n",
        "  !python bert/create_pretraining_data.py \\\n",
        "    --input_file={file} \\\n",
        "    --output_file={out_file} \\\n",
        "    --vocab_file=wpModels/vocab.eu.txt \\\n",
        "    --do_lower_case=True \\\n",
        "    --max_seq_length={MAX_SEQ_LEN} \\\n",
        "    --max_predictions_per_seq={MAX_PREDICTIONS_PER_SEQ} \\\n",
        "    --masked_lm_prob={MASKED_LM_PROB} \\\n",
        "    --random_seed=12345 \\\n",
        "    --dupe_factor=5\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_FJ66cuq4gj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "023e1939-d881-4089-cb34-2de581634e0f"
      },
      "source": [
        "# continue creating data for pretraining\n",
        "\n",
        "x = !gsutil ls gs://gurebert/gureBERT/corpus/eu/*/*.tfrecord | wc -l\n",
        "y = !gsutil ls gs://gurebert/gureBERT/corpus/eu/*/*.sent_splited | wc -l\n",
        "\n",
        "if (x == y):\n",
        "  print('All ptretraining done!')\n",
        "else:\n",
        "  # TODO\n",
        "  none\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All ptretraining done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhJGvKq6_Pkd",
        "colab_type": "code",
        "outputId": "8ef93e00-3e4c-4643-b2b3-60312a26ee06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "OUTPUT_GCS = 'gs://gurebert/gureBERT/wordpiece/model'\n",
        "\n",
        "MAX_SEQ_LEN = 128\n",
        "#MAX_SEQ_LEN = 512\n",
        "MASKED_LM_PROB = 0.15\n",
        "MAX_PREDICTIONS_PER_SEQ = round(MAX_SEQ_LEN * MASKED_LM_PROB)\n",
        "\n",
        "files = !gsutil ls gs://gurebert/gureBERT/corpus/eu/*/*.tfrecord\n",
        "files = \",\".join(files)\n",
        "\n",
        "# OR copy locally\n",
        "#!gsutil -m cp -r gs://gurebert/gureBERT/corpus/eu/*/*.tfrecord /tmp\n",
        "#files = glob.glob(f'/tmp/*.tfrecord')\n",
        "#files = \",\".join(files)\n",
        "\n",
        "##files = '/tmp/wiki_35.sent_splited.tfrecord'\n",
        "\n",
        "bert_config = {\n",
        "  \"attention_probs_dropout_prob\": 0.1,\n",
        "  \"directionality\": \"bidi\",\n",
        "  \"hidden_act\": \"gelu\",\n",
        "  \"hidden_dropout_prob\": 0.1,\n",
        "  \"hidden_size\": 768,\n",
        "  \"initializer_range\": 0.02,\n",
        "  \"intermediate_size\": 3072,\n",
        "  \"max_position_embeddings\": 512,\n",
        "  \"num_attention_heads\": 12,\n",
        "  \"num_hidden_layers\": 12,\n",
        "  \"pooler_fc_size\": 768,\n",
        "  \"pooler_num_attention_heads\": 12,\n",
        "  \"pooler_num_fc_layers\": 3,\n",
        "  \"pooler_size_per_head\": 128,\n",
        "  \"pooler_type\": \"first_token_transform\",\n",
        "  \"type_vocab_size\": 2,\n",
        "  \"vocab_size\": 32000\n",
        "}\n",
        "\n",
        "\n",
        "import json\n",
        "with open('bert_config.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(bert_config, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "!python bert/run_pretraining.py \\\n",
        "  --input_file={files} \\\n",
        "  --output_dir={OUTPUT_GCS} \\\n",
        "  --do_train=True \\\n",
        "  --do_eval=True \\\n",
        "  --bert_config_file=bert_config.json \\\n",
        "  --train_batch_size=64 \\\n",
        "  --max_seq_length={MAX_SEQ_LEN} \\\n",
        "  --max_predictions_per_seq={MAX_PREDICTIONS_PER_SEQ} \\\n",
        "  --num_train_steps=10000 \\\n",
        "  --num_warmup_steps=10000 \\\n",
        "  --save_checkpoints_steps=10000 \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --use_tpu=True \\\n",
        "  --tpu_name={TPU_ADDRESS} \\\n",
        "  #--num_train_steps=1000000 \\\n",
        "  #--init_checkpoint={OUTPUT_GCS} \\\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0713 17:26:42.971759 140353320949632 deprecation_wrapper.py:119] From /content/gureBERT/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0713 17:26:42.972923 140353320949632 deprecation_wrapper.py:119] From bert/run_pretraining.py:493: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0713 17:26:42.973571 140353320949632 deprecation_wrapper.py:119] From bert/run_pretraining.py:407: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0713 17:26:42.973752 140353320949632 deprecation_wrapper.py:119] From bert/run_pretraining.py:407: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0713 17:26:42.973908 140353320949632 deprecation_wrapper.py:119] From /content/gureBERT/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0713 17:26:42.974625 140353320949632 deprecation_wrapper.py:119] From bert/run_pretraining.py:414: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0713 17:26:45.090973 140353320949632 deprecation_wrapper.py:119] From bert/run_pretraining.py:418: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0713 17:28:24.606326 140353320949632 deprecation_wrapper.py:119] From bert/run_pretraining.py:420: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "I0713 17:28:24.606679 140353320949632 run_pretraining.py:420] *** Input Files ***\n",
            "I0713 17:28:24.606795 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_00.sent_splited.tfrecord\n",
            "I0713 17:28:24.606883 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_01.sent_splited.tfrecord\n",
            "I0713 17:28:24.606975 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_02.sent_splited.tfrecord\n",
            "I0713 17:28:24.607048 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_03.sent_splited.tfrecord\n",
            "I0713 17:28:24.607133 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_04.sent_splited.tfrecord\n",
            "I0713 17:28:24.607204 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_05.sent_splited.tfrecord\n",
            "I0713 17:28:24.607267 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_06.sent_splited.tfrecord\n",
            "I0713 17:28:24.607329 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_07.sent_splited.tfrecord\n",
            "I0713 17:28:24.607402 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_08.sent_splited.tfrecord\n",
            "I0713 17:28:24.607475 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_09.sent_splited.tfrecord\n",
            "I0713 17:28:24.607538 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_10.sent_splited.tfrecord\n",
            "I0713 17:28:24.607616 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_11.sent_splited.tfrecord\n",
            "I0713 17:28:24.607680 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_12.sent_splited.tfrecord\n",
            "I0713 17:28:24.607742 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_13.sent_splited.tfrecord\n",
            "I0713 17:28:24.607803 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_14.sent_splited.tfrecord\n",
            "I0713 17:28:24.607864 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_15.sent_splited.tfrecord\n",
            "I0713 17:28:24.607925 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_16.sent_splited.tfrecord\n",
            "I0713 17:28:24.607987 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_17.sent_splited.tfrecord\n",
            "I0713 17:28:24.608047 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_18.sent_splited.tfrecord\n",
            "I0713 17:28:24.608116 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_19.sent_splited.tfrecord\n",
            "I0713 17:28:24.608178 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_20.sent_splited.tfrecord\n",
            "I0713 17:28:24.608239 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_21.sent_splited.tfrecord\n",
            "I0713 17:28:24.608301 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_22.sent_splited.tfrecord\n",
            "I0713 17:28:24.608362 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_23.sent_splited.tfrecord\n",
            "I0713 17:28:24.608422 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_24.sent_splited.tfrecord\n",
            "I0713 17:28:24.608483 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_25.sent_splited.tfrecord\n",
            "I0713 17:28:24.608550 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_26.sent_splited.tfrecord\n",
            "I0713 17:28:24.608626 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_27.sent_splited.tfrecord\n",
            "I0713 17:28:24.608688 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_28.sent_splited.tfrecord\n",
            "I0713 17:28:24.608750 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_29.sent_splited.tfrecord\n",
            "I0713 17:28:24.608810 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_30.sent_splited.tfrecord\n",
            "I0713 17:28:24.608871 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_31.sent_splited.tfrecord\n",
            "I0713 17:28:24.608932 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_32.sent_splited.tfrecord\n",
            "I0713 17:28:24.608994 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_33.sent_splited.tfrecord\n",
            "I0713 17:28:24.609057 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_34.sent_splited.tfrecord\n",
            "I0713 17:28:24.609124 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_35.sent_splited.tfrecord\n",
            "I0713 17:28:24.609185 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_36.sent_splited.tfrecord\n",
            "I0713 17:28:24.609246 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_37.sent_splited.tfrecord\n",
            "I0713 17:28:24.609306 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_38.sent_splited.tfrecord\n",
            "I0713 17:28:24.609366 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_39.sent_splited.tfrecord\n",
            "I0713 17:28:24.609427 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_40.sent_splited.tfrecord\n",
            "I0713 17:28:24.609487 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_41.sent_splited.tfrecord\n",
            "I0713 17:28:24.609561 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_42.sent_splited.tfrecord\n",
            "I0713 17:28:24.609651 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_43.sent_splited.tfrecord\n",
            "I0713 17:28:24.609714 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_44.sent_splited.tfrecord\n",
            "I0713 17:28:24.609773 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_45.sent_splited.tfrecord\n",
            "I0713 17:28:24.609833 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_46.sent_splited.tfrecord\n",
            "I0713 17:28:24.609893 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_47.sent_splited.tfrecord\n",
            "I0713 17:28:24.609962 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_48.sent_splited.tfrecord\n",
            "I0713 17:28:24.610032 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_49.sent_splited.tfrecord\n",
            "I0713 17:28:24.610100 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_50.sent_splited.tfrecord\n",
            "I0713 17:28:24.610160 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_51.sent_splited.tfrecord\n",
            "I0713 17:28:24.610219 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_52.sent_splited.tfrecord\n",
            "I0713 17:28:24.610279 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_53.sent_splited.tfrecord\n",
            "I0713 17:28:24.610340 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_54.sent_splited.tfrecord\n",
            "I0713 17:28:24.610399 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_55.sent_splited.tfrecord\n",
            "I0713 17:28:24.610459 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_56.sent_splited.tfrecord\n",
            "I0713 17:28:24.610519 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_57.sent_splited.tfrecord\n",
            "I0713 17:28:24.610592 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_58.sent_splited.tfrecord\n",
            "I0713 17:28:24.610659 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_59.sent_splited.tfrecord\n",
            "I0713 17:28:24.610721 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_60.sent_splited.tfrecord\n",
            "I0713 17:28:24.610785 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_61.sent_splited.tfrecord\n",
            "I0713 17:28:24.610846 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_62.sent_splited.tfrecord\n",
            "I0713 17:28:24.610907 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_63.sent_splited.tfrecord\n",
            "I0713 17:28:24.610968 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_64.sent_splited.tfrecord\n",
            "I0713 17:28:24.611029 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_65.sent_splited.tfrecord\n",
            "I0713 17:28:24.611108 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_66.sent_splited.tfrecord\n",
            "I0713 17:28:24.611181 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_67.sent_splited.tfrecord\n",
            "I0713 17:28:24.611244 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_68.sent_splited.tfrecord\n",
            "I0713 17:28:24.611305 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_69.sent_splited.tfrecord\n",
            "I0713 17:28:24.611366 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_70.sent_splited.tfrecord\n",
            "I0713 17:28:24.611427 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_71.sent_splited.tfrecord\n",
            "I0713 17:28:24.611488 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_72.sent_splited.tfrecord\n",
            "I0713 17:28:24.611550 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_73.sent_splited.tfrecord\n",
            "I0713 17:28:24.611630 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_74.sent_splited.tfrecord\n",
            "I0713 17:28:24.611691 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_75.sent_splited.tfrecord\n",
            "I0713 17:28:24.611752 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_76.sent_splited.tfrecord\n",
            "I0713 17:28:24.611823 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_77.sent_splited.tfrecord\n",
            "I0713 17:28:24.611906 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_78.sent_splited.tfrecord\n",
            "I0713 17:28:24.611976 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_79.sent_splited.tfrecord\n",
            "I0713 17:28:24.612039 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_80.sent_splited.tfrecord\n",
            "I0713 17:28:24.612108 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_81.sent_splited.tfrecord\n",
            "I0713 17:28:24.612169 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_82.sent_splited.tfrecord\n",
            "I0713 17:28:24.612229 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_83.sent_splited.tfrecord\n",
            "I0713 17:28:24.612291 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_84.sent_splited.tfrecord\n",
            "I0713 17:28:24.612352 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_85.sent_splited.tfrecord\n",
            "I0713 17:28:24.612412 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_86.sent_splited.tfrecord\n",
            "I0713 17:28:24.612473 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_87.sent_splited.tfrecord\n",
            "I0713 17:28:24.612536 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_88.sent_splited.tfrecord\n",
            "I0713 17:28:24.612622 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_89.sent_splited.tfrecord\n",
            "I0713 17:28:24.612694 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_90.sent_splited.tfrecord\n",
            "I0713 17:28:24.612757 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_91.sent_splited.tfrecord\n",
            "I0713 17:28:24.612818 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_92.sent_splited.tfrecord\n",
            "I0713 17:28:24.612879 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_93.sent_splited.tfrecord\n",
            "I0713 17:28:24.612940 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_94.sent_splited.tfrecord\n",
            "I0713 17:28:24.613002 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_95.sent_splited.tfrecord\n",
            "I0713 17:28:24.613063 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_96.sent_splited.tfrecord\n",
            "I0713 17:28:24.613130 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_97.sent_splited.tfrecord\n",
            "I0713 17:28:24.613192 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_98.sent_splited.tfrecord\n",
            "I0713 17:28:24.613252 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_99.sent_splited.tfrecord\n",
            "I0713 17:28:24.613312 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_00.sent_splited.tfrecord\n",
            "I0713 17:28:24.613373 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_01.sent_splited.tfrecord\n",
            "I0713 17:28:24.613434 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_02.sent_splited.tfrecord\n",
            "I0713 17:28:24.613495 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_03.sent_splited.tfrecord\n",
            "I0713 17:28:24.613557 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_04.sent_splited.tfrecord\n",
            "I0713 17:28:24.613633 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_05.sent_splited.tfrecord\n",
            "I0713 17:28:24.613714 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_06.sent_splited.tfrecord\n",
            "I0713 17:28:24.613765 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_07.sent_splited.tfrecord\n",
            "I0713 17:28:24.613815 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_08.sent_splited.tfrecord\n",
            "I0713 17:28:24.613863 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_09.sent_splited.tfrecord\n",
            "I0713 17:28:24.613912 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_10.sent_splited.tfrecord\n",
            "I0713 17:28:24.613960 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_11.sent_splited.tfrecord\n",
            "I0713 17:28:24.614010 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_12.sent_splited.tfrecord\n",
            "I0713 17:28:24.614058 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_13.sent_splited.tfrecord\n",
            "I0713 17:28:24.614113 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_14.sent_splited.tfrecord\n",
            "I0713 17:28:24.614161 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_15.sent_splited.tfrecord\n",
            "I0713 17:28:24.614209 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_16.sent_splited.tfrecord\n",
            "I0713 17:28:24.614257 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_17.sent_splited.tfrecord\n",
            "I0713 17:28:24.614305 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_18.sent_splited.tfrecord\n",
            "I0713 17:28:24.614354 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_19.sent_splited.tfrecord\n",
            "I0713 17:28:24.614402 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_20.sent_splited.tfrecord\n",
            "I0713 17:28:24.614451 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_21.sent_splited.tfrecord\n",
            "I0713 17:28:24.621766 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_22.sent_splited.tfrecord\n",
            "I0713 17:28:24.621971 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_23.sent_splited.tfrecord\n",
            "I0713 17:28:24.622149 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_24.sent_splited.tfrecord\n",
            "I0713 17:28:24.622241 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_25.sent_splited.tfrecord\n",
            "I0713 17:28:24.622321 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_26.sent_splited.tfrecord\n",
            "I0713 17:28:24.622394 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_27.sent_splited.tfrecord\n",
            "I0713 17:28:24.622467 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_28.sent_splited.tfrecord\n",
            "I0713 17:28:24.622536 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_29.sent_splited.tfrecord\n",
            "I0713 17:28:24.622633 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_30.sent_splited.tfrecord\n",
            "I0713 17:28:24.622707 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_31.sent_splited.tfrecord\n",
            "I0713 17:28:24.622780 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_32.sent_splited.tfrecord\n",
            "I0713 17:28:24.622862 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_33.sent_splited.tfrecord\n",
            "I0713 17:28:24.622942 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_34.sent_splited.tfrecord\n",
            "I0713 17:28:24.623030 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_35.sent_splited.tfrecord\n",
            "I0713 17:28:24.623112 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_36.sent_splited.tfrecord\n",
            "I0713 17:28:24.623191 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_37.sent_splited.tfrecord\n",
            "I0713 17:28:24.623271 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_38.sent_splited.tfrecord\n",
            "I0713 17:28:24.623352 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_39.sent_splited.tfrecord\n",
            "I0713 17:28:24.623435 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_40.sent_splited.tfrecord\n",
            "I0713 17:28:24.623517 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_41.sent_splited.tfrecord\n",
            "I0713 17:28:24.623620 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_42.sent_splited.tfrecord\n",
            "I0713 17:28:24.623706 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_43.sent_splited.tfrecord\n",
            "I0713 17:28:24.623782 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_44.sent_splited.tfrecord\n",
            "I0713 17:28:24.623859 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_45.sent_splited.tfrecord\n",
            "I0713 17:28:24.623943 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_46.sent_splited.tfrecord\n",
            "I0713 17:28:24.624035 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_47.sent_splited.tfrecord\n",
            "I0713 17:28:24.624119 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_48.sent_splited.tfrecord\n",
            "I0713 17:28:24.624205 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_49.sent_splited.tfrecord\n",
            "I0713 17:28:24.624287 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_50.sent_splited.tfrecord\n",
            "I0713 17:28:24.624368 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_51.sent_splited.tfrecord\n",
            "I0713 17:28:24.624449 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_52.sent_splited.tfrecord\n",
            "I0713 17:28:24.624531 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_53.sent_splited.tfrecord\n",
            "I0713 17:28:24.624634 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_54.sent_splited.tfrecord\n",
            "I0713 17:28:24.624720 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_55.sent_splited.tfrecord\n",
            "I0713 17:28:24.624802 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_56.sent_splited.tfrecord\n",
            "I0713 17:28:24.624885 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_57.sent_splited.tfrecord\n",
            "I0713 17:28:24.624965 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_58.sent_splited.tfrecord\n",
            "I0713 17:28:24.625059 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_59.sent_splited.tfrecord\n",
            "I0713 17:28:24.625142 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_60.sent_splited.tfrecord\n",
            "I0713 17:28:24.625229 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_61.sent_splited.tfrecord\n",
            "I0713 17:28:24.625310 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_62.sent_splited.tfrecord\n",
            "I0713 17:28:24.625391 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_63.sent_splited.tfrecord\n",
            "I0713 17:28:24.625474 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_64.sent_splited.tfrecord\n",
            "I0713 17:28:24.625556 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_65.sent_splited.tfrecord\n",
            "I0713 17:28:24.625661 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_66.sent_splited.tfrecord\n",
            "I0713 17:28:24.625744 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_67.sent_splited.tfrecord\n",
            "I0713 17:28:24.625824 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_68.sent_splited.tfrecord\n",
            "I0713 17:28:24.625906 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_69.sent_splited.tfrecord\n",
            "I0713 17:28:24.625988 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_70.sent_splited.tfrecord\n",
            "I0713 17:28:24.626085 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_71.sent_splited.tfrecord\n",
            "I0713 17:28:24.626167 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_72.sent_splited.tfrecord\n",
            "I0713 17:28:24.626250 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_73.sent_splited.tfrecord\n",
            "I0713 17:28:24.626331 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_74.sent_splited.tfrecord\n",
            "I0713 17:28:24.626411 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_75.sent_splited.tfrecord\n",
            "I0713 17:28:24.626494 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_76.sent_splited.tfrecord\n",
            "I0713 17:28:24.626573 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_77.sent_splited.tfrecord\n",
            "I0713 17:28:24.626677 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_78.sent_splited.tfrecord\n",
            "I0713 17:28:24.626758 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_79.sent_splited.tfrecord\n",
            "I0713 17:28:24.626838 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_80.sent_splited.tfrecord\n",
            "I0713 17:28:24.626919 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_81.sent_splited.tfrecord\n",
            "I0713 17:28:24.627010 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_82.sent_splited.tfrecord\n",
            "I0713 17:28:24.627093 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_83.sent_splited.tfrecord\n",
            "I0713 17:28:24.627175 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_84.sent_splited.tfrecord\n",
            "I0713 17:28:24.627256 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_85.sent_splited.tfrecord\n",
            "I0713 17:28:24.627337 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_86.sent_splited.tfrecord\n",
            "I0713 17:28:24.627417 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_87.sent_splited.tfrecord\n",
            "I0713 17:28:24.627499 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_88.sent_splited.tfrecord\n",
            "I0713 17:28:24.627599 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_89.sent_splited.tfrecord\n",
            "I0713 17:28:24.627687 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_90.sent_splited.tfrecord\n",
            "I0713 17:28:24.627767 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_91.sent_splited.tfrecord\n",
            "I0713 17:28:24.627847 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_92.sent_splited.tfrecord\n",
            "I0713 17:28:24.627928 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_93.sent_splited.tfrecord\n",
            "I0713 17:28:24.628020 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_94.sent_splited.tfrecord\n",
            "I0713 17:28:24.628104 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_95.sent_splited.tfrecord\n",
            "I0713 17:28:24.628185 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_96.sent_splited.tfrecord\n",
            "I0713 17:28:24.628264 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_97.sent_splited.tfrecord\n",
            "I0713 17:28:24.628343 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_98.sent_splited.tfrecord\n",
            "I0713 17:28:24.628424 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_99.sent_splited.tfrecord\n",
            "I0713 17:28:24.628505 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_00.sent_splited.tfrecord\n",
            "I0713 17:28:24.628602 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_01.sent_splited.tfrecord\n",
            "I0713 17:28:24.628688 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_02.sent_splited.tfrecord\n",
            "I0713 17:28:24.628767 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_03.sent_splited.tfrecord\n",
            "I0713 17:28:24.628848 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_04.sent_splited.tfrecord\n",
            "I0713 17:28:24.628928 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_05.sent_splited.tfrecord\n",
            "I0713 17:28:24.629017 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_06.sent_splited.tfrecord\n",
            "I0713 17:28:24.629101 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_07.sent_splited.tfrecord\n",
            "I0713 17:28:24.629181 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_08.sent_splited.tfrecord\n",
            "I0713 17:28:24.629262 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_09.sent_splited.tfrecord\n",
            "I0713 17:28:24.629341 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_10.sent_splited.tfrecord\n",
            "I0713 17:28:24.629420 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_11.sent_splited.tfrecord\n",
            "I0713 17:28:24.629501 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_12.sent_splited.tfrecord\n",
            "I0713 17:28:24.629599 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_13.sent_splited.tfrecord\n",
            "I0713 17:28:24.629684 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_14.sent_splited.tfrecord\n",
            "I0713 17:28:24.629765 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_15.sent_splited.tfrecord\n",
            "I0713 17:28:24.629847 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_16.sent_splited.tfrecord\n",
            "I0713 17:28:24.629928 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_17.sent_splited.tfrecord\n",
            "I0713 17:28:24.630019 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_18.sent_splited.tfrecord\n",
            "I0713 17:28:24.630104 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_19.sent_splited.tfrecord\n",
            "I0713 17:28:24.630184 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_20.sent_splited.tfrecord\n",
            "I0713 17:28:24.630264 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_21.sent_splited.tfrecord\n",
            "I0713 17:28:24.630345 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_22.sent_splited.tfrecord\n",
            "I0713 17:28:24.630428 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_23.sent_splited.tfrecord\n",
            "I0713 17:28:24.630509 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_24.sent_splited.tfrecord\n",
            "I0713 17:28:24.630608 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_25.sent_splited.tfrecord\n",
            "I0713 17:28:24.630692 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_26.sent_splited.tfrecord\n",
            "I0713 17:28:24.630771 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_27.sent_splited.tfrecord\n",
            "I0713 17:28:24.630852 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_28.sent_splited.tfrecord\n",
            "I0713 17:28:24.630933 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_29.sent_splited.tfrecord\n",
            "I0713 17:28:24.631023 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_30.sent_splited.tfrecord\n",
            "I0713 17:28:24.631108 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_31.sent_splited.tfrecord\n",
            "I0713 17:28:24.631190 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_32.sent_splited.tfrecord\n",
            "I0713 17:28:24.631272 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_33.sent_splited.tfrecord\n",
            "I0713 17:28:24.631352 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_34.sent_splited.tfrecord\n",
            "I0713 17:28:24.631431 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_35.sent_splited.tfrecord\n",
            "I0713 17:28:24.631512 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_36.sent_splited.tfrecord\n",
            "I0713 17:28:24.631609 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_37.sent_splited.tfrecord\n",
            "I0713 17:28:24.631696 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_38.sent_splited.tfrecord\n",
            "I0713 17:28:24.631776 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_39.sent_splited.tfrecord\n",
            "I0713 17:28:24.631857 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_40.sent_splited.tfrecord\n",
            "I0713 17:28:24.631938 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_41.sent_splited.tfrecord\n",
            "I0713 17:28:24.632031 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_42.sent_splited.tfrecord\n",
            "I0713 17:28:24.632115 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_43.sent_splited.tfrecord\n",
            "I0713 17:28:24.632194 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_44.sent_splited.tfrecord\n",
            "I0713 17:28:24.632274 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_45.sent_splited.tfrecord\n",
            "I0713 17:28:24.632354 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_46.sent_splited.tfrecord\n",
            "I0713 17:28:24.632436 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_47.sent_splited.tfrecord\n",
            "I0713 17:28:24.632516 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_48.sent_splited.tfrecord\n",
            "I0713 17:28:24.632613 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_49.sent_splited.tfrecord\n",
            "I0713 17:28:24.632696 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_50.sent_splited.tfrecord\n",
            "I0713 17:28:24.632775 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_51.sent_splited.tfrecord\n",
            "I0713 17:28:24.632857 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_52.sent_splited.tfrecord\n",
            "I0713 17:28:24.632936 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_53.sent_splited.tfrecord\n",
            "I0713 17:28:24.633024 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_54.sent_splited.tfrecord\n",
            "I0713 17:28:24.633115 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_55.sent_splited.tfrecord\n",
            "I0713 17:28:24.633197 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_56.sent_splited.tfrecord\n",
            "I0713 17:28:24.633279 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_57.sent_splited.tfrecord\n",
            "I0713 17:28:24.633357 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_58.sent_splited.tfrecord\n",
            "I0713 17:28:24.633437 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_59.sent_splited.tfrecord\n",
            "I0713 17:28:24.633516 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_60.sent_splited.tfrecord\n",
            "I0713 17:28:24.633615 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_61.sent_splited.tfrecord\n",
            "I0713 17:28:24.633702 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_62.sent_splited.tfrecord\n",
            "I0713 17:28:24.633782 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_63.sent_splited.tfrecord\n",
            "I0713 17:28:24.633862 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_64.sent_splited.tfrecord\n",
            "I0713 17:28:24.633943 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_65.sent_splited.tfrecord\n",
            "I0713 17:28:24.634034 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_66.sent_splited.tfrecord\n",
            "I0713 17:28:24.634117 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_67.sent_splited.tfrecord\n",
            "I0713 17:28:24.634196 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_68.sent_splited.tfrecord\n",
            "I0713 17:28:24.634275 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_69.sent_splited.tfrecord\n",
            "I0713 17:28:24.634356 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_70.sent_splited.tfrecord\n",
            "I0713 17:28:24.634438 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_71.sent_splited.tfrecord\n",
            "I0713 17:28:24.634517 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_72.sent_splited.tfrecord\n",
            "I0713 17:28:24.634615 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_73.sent_splited.tfrecord\n",
            "I0713 17:28:24.634700 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_74.sent_splited.tfrecord\n",
            "I0713 17:28:24.634782 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_75.sent_splited.tfrecord\n",
            "I0713 17:28:24.634863 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_76.sent_splited.tfrecord\n",
            "I0713 17:28:24.634943 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_77.sent_splited.tfrecord\n",
            "I0713 17:28:24.635034 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_78.sent_splited.tfrecord\n",
            "I0713 17:28:24.635118 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_79.sent_splited.tfrecord\n",
            "I0713 17:28:24.635199 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_80.sent_splited.tfrecord\n",
            "I0713 17:28:24.635292 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_81.sent_splited.tfrecord\n",
            "I0713 17:28:24.635372 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_82.sent_splited.tfrecord\n",
            "I0713 17:28:24.635451 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_83.sent_splited.tfrecord\n",
            "I0713 17:28:24.635532 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_84.sent_splited.tfrecord\n",
            "I0713 17:28:24.635632 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_85.sent_splited.tfrecord\n",
            "I0713 17:28:24.635716 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_86.sent_splited.tfrecord\n",
            "I0713 17:28:24.635797 140353320949632 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_87.sent_splited.tfrecord\n",
            "W0713 17:28:25.748508 140353320949632 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0713 17:28:26.755280 140353320949632 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fa657db69d8>) includes params argument, but params are not passed to Estimator.\n",
            "I0713 17:28:26.757000 140353320949632 estimator.py:209] Using config: {'_model_dir': 'gs://gurebert/gureBERT/wordpiece/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.51.131.226:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa66400a588>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.51.131.226:8470', '_evaluation_master': 'grpc://10.51.131.226:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7fa6640142b0>}\n",
            "I0713 17:28:26.757395 140353320949632 tpu_context.py:209] _TPUContext: eval_on_tpu True\n",
            "I0713 17:28:26.758200 140353320949632 run_pretraining.py:459] ***** Running training *****\n",
            "I0713 17:28:26.758319 140353320949632 run_pretraining.py:460]   Batch size = 64\n",
            "I0713 17:28:29.236692 140353320949632 tpu_system_metadata.py:78] Querying Tensorflow master (grpc://10.51.131.226:8470) for TPU system metadata.\n",
            "2019-07-13 17:28:29.238348: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:356] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
            "I0713 17:28:29.253072 140353320949632 tpu_system_metadata.py:148] Found TPU system:\n",
            "I0713 17:28:29.253356 140353320949632 tpu_system_metadata.py:149] *** Num TPU Cores: 8\n",
            "I0713 17:28:29.253459 140353320949632 tpu_system_metadata.py:150] *** Num TPU Workers: 1\n",
            "I0713 17:28:29.253525 140353320949632 tpu_system_metadata.py:152] *** Num TPU Cores Per Worker: 8\n",
            "I0713 17:28:29.253609 140353320949632 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 6810479753173132532)\n",
            "I0713 17:28:29.255371 140353320949632 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 14433261477188369500)\n",
            "I0713 17:28:29.255458 140353320949632 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 10471305944331051035)\n",
            "I0713 17:28:29.255527 140353320949632 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 290337485020010624)\n",
            "I0713 17:28:29.255616 140353320949632 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 8844700230351949478)\n",
            "I0713 17:28:29.255687 140353320949632 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 17633311837389007867)\n",
            "I0713 17:28:29.255753 140353320949632 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 501559178114276546)\n",
            "I0713 17:28:29.255815 140353320949632 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 7430056111459679944)\n",
            "I0713 17:28:29.255884 140353320949632 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 13593346917957416754)\n",
            "I0713 17:28:29.255945 140353320949632 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 11162654302255930259)\n",
            "I0713 17:28:29.256007 140353320949632 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 9581148650088822417)\n",
            "W0713 17:28:29.263290 140353320949632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "I0713 17:28:29.283878 140353320949632 estimator.py:1145] Calling model_fn.\n",
            "W0713 17:28:29.284548 140353320949632 deprecation_wrapper.py:119] From bert/run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0713 17:28:29.291986 140353320949632 deprecation.py:323] From bert/run_pretraining.py:368: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0713 17:28:29.292245 140353320949632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0713 17:28:29.321353 140353320949632 deprecation.py:323] From bert/run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "W0713 17:28:29.321642 140353320949632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W0713 17:28:29.323276 140353320949632 deprecation_wrapper.py:119] From bert/run_pretraining.py:393: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0713 17:28:29.329363 140353320949632 deprecation.py:323] From bert/run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "I0713 17:28:29.415695 140353320949632 run_pretraining.py:117] *** Features ***\n",
            "I0713 17:28:29.415988 140353320949632 run_pretraining.py:119]   name = input_ids, shape = (8, 128)\n",
            "I0713 17:28:29.416092 140353320949632 run_pretraining.py:119]   name = input_mask, shape = (8, 128)\n",
            "I0713 17:28:29.416176 140353320949632 run_pretraining.py:119]   name = masked_lm_ids, shape = (8, 19)\n",
            "I0713 17:28:29.416257 140353320949632 run_pretraining.py:119]   name = masked_lm_positions, shape = (8, 19)\n",
            "I0713 17:28:29.416335 140353320949632 run_pretraining.py:119]   name = masked_lm_weights, shape = (8, 19)\n",
            "I0713 17:28:29.416409 140353320949632 run_pretraining.py:119]   name = next_sentence_labels, shape = (8, 1)\n",
            "I0713 17:28:29.416484 140353320949632 run_pretraining.py:119]   name = segment_ids, shape = (8, 128)\n",
            "W0713 17:28:29.416742 140353320949632 deprecation_wrapper.py:119] From /content/gureBERT/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0713 17:28:29.418946 140353320949632 deprecation_wrapper.py:119] From /content/gureBERT/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0713 17:28:29.456125 140353320949632 deprecation_wrapper.py:119] From /content/gureBERT/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "W0713 17:28:29.656627 140353320949632 deprecation.py:506] From /content/gureBERT/bert/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0713 17:28:29.678617 140353320949632 deprecation.py:323] From /content/gureBERT/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "I0713 17:28:33.789042 140353320949632 run_pretraining.py:167] **** Trainable Variables ****\n",
            "I0713 17:28:33.789331 140353320949632 run_pretraining.py:173]   name = bert/embeddings/word_embeddings:0, shape = (32000, 768)\n",
            "I0713 17:28:33.789474 140353320949632 run_pretraining.py:173]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
            "I0713 17:28:33.789566 140353320949632 run_pretraining.py:173]   name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
            "I0713 17:28:33.789671 140353320949632 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.789757 140353320949632 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.789833 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.789911 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:28:33.789984 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.790060 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:28:33.790132 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.790207 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:28:33.790282 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.790357 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.790429 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.790499 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.790570 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:28:33.790661 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:28:33.790740 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:28:33.790815 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.790886 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.790958 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.791030 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.791103 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:28:33.791174 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.791249 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:28:33.791321 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.791395 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:28:33.791465 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.791539 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.791623 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.791695 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.791772 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:28:33.791845 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:28:33.791916 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:28:33.791989 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.792060 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.792130 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.792201 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.792276 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:28:33.792347 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.792428 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:28:33.792501 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.792574 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:28:33.792663 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.792744 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.792816 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.792885 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.792955 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:28:33.793028 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:28:33.793100 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:28:33.793174 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.793245 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.793315 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.793385 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.793459 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:28:33.793530 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.793616 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:28:33.793688 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.793775 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:28:33.793846 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.793920 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.793991 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.794060 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.794131 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:28:33.794204 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:28:33.794278 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:28:33.794351 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.794429 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.794499 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.794570 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.794658 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:28:33.794736 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.794811 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:28:33.794881 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.794953 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:28:33.795029 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.795103 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.795174 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.795245 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.795315 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:28:33.795388 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:28:33.795461 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:28:33.795534 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.795617 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.795688 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.795763 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.795835 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:28:33.795904 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.795976 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:28:33.796062 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.796157 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:28:33.796248 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.796325 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.796396 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.796466 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.796535 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:28:33.796624 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:28:33.796697 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:28:33.796785 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.796857 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.796926 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.796994 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.797067 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:28:33.797137 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.797212 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:28:33.797284 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.797357 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:28:33.797427 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.797500 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.797572 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.797656 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.797734 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:28:33.797808 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:28:33.797886 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:28:33.797959 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.798030 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.798099 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.798168 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.798242 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:28:33.798312 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.798385 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:28:33.798455 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.834129 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:28:33.834516 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.834707 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.834830 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.834935 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.835055 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:28:33.835170 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:28:33.835277 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:28:33.835387 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.835489 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.835601 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.835709 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.835830 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:28:33.835933 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.836054 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:28:33.836161 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.836270 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:28:33.836415 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.836528 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.836653 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.836769 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.836873 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:28:33.836982 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:28:33.837084 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:28:33.837203 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.837310 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.837414 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.837516 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.837642 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:28:33.837758 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.837870 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:28:33.837983 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.838093 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:28:33.838199 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.838309 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.838411 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.838511 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.838629 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:28:33.838752 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:28:33.838858 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:28:33.838968 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.839084 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.839186 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.839289 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.839398 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:28:33.839499 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.839627 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:28:33.839747 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.839863 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:28:33.839987 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.840107 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.840214 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.840325 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.840429 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:28:33.840539 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:28:33.840666 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:28:33.840786 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.840893 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.840996 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.841096 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.841218 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:28:33.841325 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.841434 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:28:33.841536 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.841664 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:28:33.841784 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.841893 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.841995 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.842096 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.842198 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:28:33.842307 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:28:33.842411 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:28:33.842520 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.842642 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.842754 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.842858 140353320949632 run_pretraining.py:173]   name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.842966 140353320949632 run_pretraining.py:173]   name = bert/pooler/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.843068 140353320949632 run_pretraining.py:173]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:28:33.843173 140353320949632 run_pretraining.py:173]   name = cls/predictions/transform/dense/bias:0, shape = (768,)\n",
            "I0713 17:28:33.843286 140353320949632 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:28:33.843392 140353320949632 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:28:33.843493 140353320949632 run_pretraining.py:173]   name = cls/predictions/output_bias:0, shape = (32000,)\n",
            "I0713 17:28:33.843612 140353320949632 run_pretraining.py:173]   name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n",
            "I0713 17:28:33.843733 140353320949632 run_pretraining.py:173]   name = cls/seq_relationship/output_bias:0, shape = (2,)\n",
            "W0713 17:28:33.843945 140353320949632 deprecation_wrapper.py:119] From /content/gureBERT/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0713 17:28:33.845927 140353320949632 deprecation_wrapper.py:119] From /content/gureBERT/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "W0713 17:28:33.854159 140353320949632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0713 17:28:34.216490 140353320949632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "I0713 17:28:48.709119 140353320949632 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "I0713 17:28:49.394118 140353320949632 estimator.py:1147] Done calling model_fn.\n",
            "I0713 17:28:53.111794 140353320949632 tpu_estimator.py:499] TPU job name worker\n",
            "I0713 17:28:54.581773 140353320949632 monitored_session.py:240] Graph was finalized.\n",
            "W0713 17:28:54.720934 140353320949632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "I0713 17:28:54.876752 140353320949632 saver.py:1280] Restoring parameters from gs://gurebert/gureBERT/wordpiece/model/model.ckpt-0\n",
            "W0713 17:29:19.577825 140353320949632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "I0713 17:29:20.946460 140353320949632 session_manager.py:500] Running local_init_op.\n",
            "I0713 17:29:21.696712 140353320949632 session_manager.py:502] Done running local_init_op.\n",
            "I0713 17:29:33.232468 140353320949632 basic_session_run_hooks.py:606] Saving checkpoints for 0 into gs://gurebert/gureBERT/wordpiece/model/model.ckpt.\n",
            "W0713 17:30:00.939932 140353320949632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:741: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "I0713 17:30:02.496871 140353320949632 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "I0713 17:30:02.498027 140353320949632 session_support.py:332] Installing graceful shutdown hook.\n",
            "2019-07-13 17:30:02.498469: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:356] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
            "I0713 17:30:02.503527 140353320949632 session_support.py:82] Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "I0713 17:30:02.505770 140353320949632 session_support.py:105] Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "I0713 17:30:02.509414 140353320949632 tpu_estimator.py:557] Init TPU system\n",
            "I0713 17:30:09.931879 140353320949632 tpu_estimator.py:566] Initialized TPU in 7 seconds\n",
            "I0713 17:30:09.932706 140352172975872 tpu_estimator.py:514] Starting infeed thread controller.\n",
            "I0713 17:30:09.933320 140352146761472 tpu_estimator.py:533] Starting outfeed thread controller.\n",
            "I0713 17:30:10.735613 140353320949632 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 17:30:10.736678 140353320949632 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 17:30:44.407528 140352146761472 tpu_estimator.py:275] Outfeed finished for iteration (0, 0)\n",
            "I0713 17:31:44.423559 140352146761472 tpu_estimator.py:275] Outfeed finished for iteration (0, 938)\n",
            "I0713 17:31:50.006963 140353320949632 basic_session_run_hooks.py:262] loss = 6.655466, step = 1000\n",
            "I0713 17:31:50.009837 140353320949632 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 17:31:50.010086 140353320949632 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 17:32:44.473173 140352146761472 tpu_estimator.py:275] Outfeed finished for iteration (1, 719)\n",
            "I0713 17:33:03.167922 140353320949632 basic_session_run_hooks.py:260] loss = 4.70508, step = 2000 (73.161 sec)\n",
            "I0713 17:33:03.169622 140353320949632 tpu_estimator.py:2159] global_step/sec: 13.6685\n",
            "I0713 17:33:03.170722 140353320949632 tpu_estimator.py:2160] examples/sec: 874.783\n",
            "I0713 17:33:03.172482 140353320949632 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 17:33:03.172725 140353320949632 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 17:33:44.481641 140352146761472 tpu_estimator.py:275] Outfeed finished for iteration (2, 625)\n",
            "I0713 17:34:09.201702 140353320949632 basic_session_run_hooks.py:260] loss = 3.6279063, step = 3000 (66.034 sec)\n",
            "I0713 17:34:09.203910 140353320949632 tpu_estimator.py:2159] global_step/sec: 15.1437\n",
            "I0713 17:34:09.204119 140353320949632 tpu_estimator.py:2160] examples/sec: 969.194\n",
            "I0713 17:34:10.168267 140353320949632 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 17:34:10.168649 140353320949632 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 17:34:44.491786 140352146761472 tpu_estimator.py:275] Outfeed finished for iteration (3, 516)\n",
            "I0713 17:35:16.140819 140353320949632 basic_session_run_hooks.py:260] loss = 4.1597767, step = 4000 (66.939 sec)\n",
            "I0713 17:35:16.142759 140353320949632 tpu_estimator.py:2159] global_step/sec: 14.939\n",
            "I0713 17:35:16.142958 140353320949632 tpu_estimator.py:2160] examples/sec: 956.096\n",
            "I0713 17:35:16.144468 140353320949632 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 17:35:16.144713 140353320949632 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 17:35:44.539440 140352146761472 tpu_estimator.py:275] Outfeed finished for iteration (4, 423)\n",
            "I0713 17:36:22.205563 140353320949632 basic_session_run_hooks.py:260] loss = 4.8934774, step = 5000 (66.065 sec)\n",
            "I0713 17:36:22.207532 140353320949632 tpu_estimator.py:2159] global_step/sec: 15.1367\n",
            "I0713 17:36:22.207763 140353320949632 tpu_estimator.py:2160] examples/sec: 968.747\n",
            "I0713 17:36:23.107309 140353320949632 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 17:36:23.107857 140353320949632 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 17:36:44.598621 140352146761472 tpu_estimator.py:275] Outfeed finished for iteration (5, 315)\n",
            "I0713 17:37:29.098014 140353320949632 basic_session_run_hooks.py:260] loss = 2.8240771, step = 6000 (66.892 sec)\n",
            "I0713 17:37:29.099566 140353320949632 tpu_estimator.py:2159] global_step/sec: 14.9494\n",
            "I0713 17:37:29.099776 140353320949632 tpu_estimator.py:2160] examples/sec: 956.764\n",
            "I0713 17:37:29.101164 140353320949632 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 17:37:29.101361 140353320949632 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 17:37:44.653658 140352146761472 tpu_estimator.py:275] Outfeed finished for iteration (6, 223)\n",
            "I0713 17:38:35.969612 140353320949632 basic_session_run_hooks.py:260] loss = 4.447196, step = 7000 (66.872 sec)\n",
            "I0713 17:38:35.971429 140353320949632 tpu_estimator.py:2159] global_step/sec: 14.954\n",
            "I0713 17:38:35.971670 140353320949632 tpu_estimator.py:2160] examples/sec: 957.054\n",
            "I0713 17:38:35.973289 140353320949632 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 17:38:35.973514 140353320949632 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 17:38:44.676368 140352146761472 tpu_estimator.py:275] Outfeed finished for iteration (7, 115)\n",
            "I0713 17:39:41.975937 140353320949632 basic_session_run_hooks.py:260] loss = 4.9955716, step = 8000 (66.006 sec)\n",
            "I0713 17:39:41.977604 140353320949632 tpu_estimator.py:2159] global_step/sec: 15.1501\n",
            "I0713 17:39:41.977813 140353320949632 tpu_estimator.py:2160] examples/sec: 969.606\n",
            "I0713 17:39:41.978985 140353320949632 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 17:39:41.979292 140353320949632 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 17:39:44.714118 140352146761472 tpu_estimator.py:275] Outfeed finished for iteration (8, 22)\n",
            "I0713 17:40:44.728682 140352146761472 tpu_estimator.py:275] Outfeed finished for iteration (8, 960)\n",
            "I0713 17:40:47.982326 140353320949632 basic_session_run_hooks.py:260] loss = 3.9324107, step = 9000 (66.006 sec)\n",
            "I0713 17:40:47.984425 140353320949632 tpu_estimator.py:2159] global_step/sec: 15.15\n",
            "I0713 17:40:47.984755 140353320949632 tpu_estimator.py:2160] examples/sec: 969.598\n",
            "I0713 17:40:48.937489 140353320949632 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 17:40:48.938090 140353320949632 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 17:41:44.759871 140352146761472 tpu_estimator.py:275] Outfeed finished for iteration (9, 853)\n",
            "I0713 17:41:54.869934 140353320949632 basic_session_run_hooks.py:606] Saving checkpoints for 10000 into gs://gurebert/gureBERT/wordpiece/model/model.ckpt.\n",
            "I0713 17:42:20.447002 140353320949632 basic_session_run_hooks.py:260] loss = 3.5915267, step = 10000 (92.465 sec)\n",
            "I0713 17:42:20.448996 140353320949632 tpu_estimator.py:2159] global_step/sec: 10.8149\n",
            "I0713 17:42:20.449181 140353320949632 tpu_estimator.py:2160] examples/sec: 692.156\n",
            "I0713 17:42:21.406643 140353320949632 tpu_estimator.py:598] Stop infeed thread controller\n",
            "I0713 17:42:21.406980 140353320949632 tpu_estimator.py:430] Shutting down InfeedController thread.\n",
            "I0713 17:42:21.407279 140352172975872 tpu_estimator.py:425] InfeedController received shutdown signal, stopping.\n",
            "I0713 17:42:21.407649 140352172975872 tpu_estimator.py:530] Infeed thread finished, shutting down.\n",
            "I0713 17:42:21.407921 140353320949632 error_handling.py:96] infeed marked as finished\n",
            "I0713 17:42:21.408203 140353320949632 tpu_estimator.py:602] Stop output thread controller\n",
            "I0713 17:42:21.408304 140353320949632 tpu_estimator.py:430] Shutting down OutfeedController thread.\n",
            "I0713 17:42:21.408543 140352146761472 tpu_estimator.py:425] OutfeedController received shutdown signal, stopping.\n",
            "I0713 17:42:21.408766 140352146761472 tpu_estimator.py:541] Outfeed thread finished, shutting down.\n",
            "I0713 17:42:21.408955 140353320949632 error_handling.py:96] outfeed marked as finished\n",
            "I0713 17:42:21.409176 140353320949632 tpu_estimator.py:606] Shutdown TPU system.\n",
            "I0713 17:42:22.952620 140353320949632 estimator.py:368] Loss for final step: 3.5915267.\n",
            "I0713 17:42:22.953873 140353320949632 error_handling.py:96] training_loop marked as finished\n",
            "I0713 17:42:22.954046 140353320949632 run_pretraining.py:469] ***** Running evaluation *****\n",
            "I0713 17:42:22.954136 140353320949632 run_pretraining.py:470]   Batch size = 8\n",
            "I0713 17:42:23.757878 140353320949632 estimator.py:1145] Calling model_fn.\n",
            "I0713 17:42:23.867154 140353320949632 run_pretraining.py:117] *** Features ***\n",
            "I0713 17:42:23.867467 140353320949632 run_pretraining.py:119]   name = input_ids, shape = (1, 128)\n",
            "I0713 17:42:23.867565 140353320949632 run_pretraining.py:119]   name = input_mask, shape = (1, 128)\n",
            "I0713 17:42:23.867657 140353320949632 run_pretraining.py:119]   name = masked_lm_ids, shape = (1, 19)\n",
            "I0713 17:42:23.867735 140353320949632 run_pretraining.py:119]   name = masked_lm_positions, shape = (1, 19)\n",
            "I0713 17:42:23.867832 140353320949632 run_pretraining.py:119]   name = masked_lm_weights, shape = (1, 19)\n",
            "I0713 17:42:23.867895 140353320949632 run_pretraining.py:119]   name = next_sentence_labels, shape = (1, 1)\n",
            "I0713 17:42:23.867989 140353320949632 run_pretraining.py:119]   name = segment_ids, shape = (1, 128)\n",
            "I0713 17:42:28.137019 140353320949632 run_pretraining.py:167] **** Trainable Variables ****\n",
            "I0713 17:42:28.137285 140353320949632 run_pretraining.py:173]   name = bert/embeddings/word_embeddings:0, shape = (32000, 768)\n",
            "I0713 17:42:28.137409 140353320949632 run_pretraining.py:173]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
            "I0713 17:42:28.137501 140353320949632 run_pretraining.py:173]   name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
            "I0713 17:42:28.137619 140353320949632 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.137726 140353320949632 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.137805 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.137886 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:42:28.137960 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.138039 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:42:28.138114 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.138190 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:42:28.138265 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.138341 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.138414 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.138485 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.138565 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:42:28.138663 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:42:28.138737 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:42:28.138813 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.138886 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.138958 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.139033 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.139110 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:42:28.139181 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.139256 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:42:28.139328 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.139402 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:42:28.139474 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.139555 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.139645 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.139717 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.139788 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:42:28.139863 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:42:28.139932 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:42:28.140007 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.140081 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.140151 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.140224 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.140299 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:42:28.140370 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.140446 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:42:28.140524 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.140612 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:42:28.140685 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.140759 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.140831 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.140903 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.140974 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:42:28.141064 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:42:28.141149 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:42:28.141225 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.141297 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.141369 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.141440 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.141522 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:42:28.141607 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.141685 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:42:28.141765 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.141841 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:42:28.141914 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.141991 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.142066 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.142145 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.142217 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:42:28.142292 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:42:28.142364 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:42:28.142438 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.142518 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.142604 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.142679 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.142754 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:42:28.142826 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.142900 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:42:28.142971 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.143048 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:42:28.143120 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.143194 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.143264 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.143334 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.143406 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:42:28.143480 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:42:28.143559 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:42:28.143657 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.143730 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.143801 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.143880 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.143956 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:42:28.144028 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.144103 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:42:28.144173 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.144247 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:42:28.144319 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.144392 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.144462 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.144537 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.144621 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:42:28.144698 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:42:28.144769 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:42:28.144843 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.144913 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.144983 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.145056 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.145130 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:42:28.145202 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.145276 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:42:28.145347 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.145420 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:42:28.145493 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.145573 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.145659 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.145730 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.145800 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:42:28.145874 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:42:28.145947 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:42:28.146020 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.146093 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.146164 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.146235 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.146308 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:42:28.146379 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.146454 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:42:28.146538 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.232185 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:42:28.232478 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.232662 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.232779 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.232882 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.232988 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:42:28.233184 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:42:28.233291 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:42:28.233401 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.233528 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.233668 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.233778 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.233892 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:42:28.234000 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.234126 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:42:28.234233 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.234344 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:42:28.234450 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.234561 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.234687 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.234792 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.234897 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:42:28.235028 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:42:28.235139 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:42:28.235249 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.235352 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.235453 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.235557 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.235697 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:42:28.235807 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.235915 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:42:28.236031 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.236143 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:42:28.236247 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.236354 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.236459 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.236561 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.236684 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:42:28.236786 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:42:28.236891 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:42:28.236999 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.237117 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.237221 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.237324 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.237430 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:42:28.237534 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.237663 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:42:28.237769 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.237875 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:42:28.237978 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.238101 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.238204 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.238303 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.238415 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:42:28.238524 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:42:28.238645 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:42:28.238754 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.238858 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.238960 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.239071 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.239180 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
            "I0713 17:42:28.239283 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.239388 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
            "I0713 17:42:28.239490 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.239615 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
            "I0713 17:42:28.239722 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.239829 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.239932 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.240045 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.240148 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0713 17:42:28.240255 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0713 17:42:28.240359 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0713 17:42:28.240468 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.240570 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.240694 140353320949632 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.240798 140353320949632 run_pretraining.py:173]   name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.240906 140353320949632 run_pretraining.py:173]   name = bert/pooler/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.241044 140353320949632 run_pretraining.py:173]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n",
            "I0713 17:42:28.241162 140353320949632 run_pretraining.py:173]   name = cls/predictions/transform/dense/bias:0, shape = (768,)\n",
            "I0713 17:42:28.241268 140353320949632 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n",
            "I0713 17:42:28.241368 140353320949632 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n",
            "I0713 17:42:28.241468 140353320949632 run_pretraining.py:173]   name = cls/predictions/output_bias:0, shape = (32000,)\n",
            "I0713 17:42:28.241600 140353320949632 run_pretraining.py:173]   name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n",
            "I0713 17:42:28.241714 140353320949632 run_pretraining.py:173]   name = cls/seq_relationship/output_bias:0, shape = (2,)\n",
            "W0713 17:42:28.658957 140353320949632 deprecation_wrapper.py:119] From bert/run_pretraining.py:198: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
            "\n",
            "W0713 17:42:28.677052 140353320949632 deprecation_wrapper.py:119] From bert/run_pretraining.py:202: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "I0713 17:42:29.735422 140353320949632 estimator.py:1147] Done calling model_fn.\n",
            "I0713 17:42:29.755087 140353320949632 evaluation.py:255] Starting evaluation at 2019-07-13T17:42:29Z\n",
            "I0713 17:42:29.755349 140353320949632 tpu_estimator.py:499] TPU job name worker\n",
            "I0713 17:42:30.297064 140353320949632 monitored_session.py:240] Graph was finalized.\n",
            "I0713 17:42:30.474644 140353320949632 saver.py:1280] Restoring parameters from gs://gurebert/gureBERT/wordpiece/model/model.ckpt-10000\n",
            "I0713 17:42:55.593979 140353320949632 session_manager.py:500] Running local_init_op.\n",
            "I0713 17:42:55.782503 140353320949632 session_manager.py:502] Done running local_init_op.\n",
            "I0713 17:42:56.227984 140353320949632 tpu_estimator.py:557] Init TPU system\n",
            "I0713 17:43:04.609243 140353320949632 tpu_estimator.py:566] Initialized TPU in 8 seconds\n",
            "I0713 17:43:04.610057 140352366974720 tpu_estimator.py:514] Starting infeed thread controller.\n",
            "I0713 17:43:04.610400 140352339449600 tpu_estimator.py:533] Starting outfeed thread controller.\n",
            "I0713 17:43:04.825282 140353320949632 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "I0713 17:43:05.000463 140353320949632 tpu_estimator.py:590] Enqueue next (100) batch(es) of data to infeed.\n",
            "I0713 17:43:05.000934 140353320949632 tpu_estimator.py:594] Dequeue next (100) batch(es) of data from outfeed.\n",
            "I0713 17:43:09.277999 140352339449600 tpu_estimator.py:275] Outfeed finished for iteration (0, 0)\n",
            "I0713 17:43:11.157320 140353320949632 evaluation.py:167] Evaluation [100/100]\n",
            "I0713 17:43:11.157705 140353320949632 tpu_estimator.py:598] Stop infeed thread controller\n",
            "I0713 17:43:11.157823 140353320949632 tpu_estimator.py:430] Shutting down InfeedController thread.\n",
            "I0713 17:43:11.158008 140352366974720 tpu_estimator.py:425] InfeedController received shutdown signal, stopping.\n",
            "I0713 17:43:11.158104 140352366974720 tpu_estimator.py:530] Infeed thread finished, shutting down.\n",
            "I0713 17:43:11.158244 140353320949632 error_handling.py:96] infeed marked as finished\n",
            "I0713 17:43:11.158369 140353320949632 tpu_estimator.py:602] Stop output thread controller\n",
            "I0713 17:43:11.158438 140353320949632 tpu_estimator.py:430] Shutting down OutfeedController thread.\n",
            "I0713 17:43:11.871972 140352339449600 tpu_estimator.py:425] OutfeedController received shutdown signal, stopping.\n",
            "I0713 17:43:11.872321 140352339449600 tpu_estimator.py:541] Outfeed thread finished, shutting down.\n",
            "I0713 17:43:11.872503 140353320949632 error_handling.py:96] outfeed marked as finished\n",
            "I0713 17:43:11.872680 140353320949632 tpu_estimator.py:606] Shutdown TPU system.\n",
            "I0713 17:43:12.448569 140353320949632 evaluation.py:275] Finished evaluation at 2019-07-13-17:43:12\n",
            "I0713 17:43:12.448960 140353320949632 estimator.py:2039] Saving dict for global step 10000: global_step = 10000, loss = 3.7114496, masked_lm_accuracy = 0.5033093, masked_lm_loss = 3.4754658, next_sentence_accuracy = 0.89375, next_sentence_loss = 0.2630788\n",
            "I0713 17:43:17.773046 140353320949632 estimator.py:2099] Saving 'checkpoint_path' summary for global step 10000: gs://gurebert/gureBERT/wordpiece/model/model.ckpt-10000\n",
            "I0713 17:43:18.594320 140353320949632 error_handling.py:96] evaluation_loop marked as finished\n",
            "I0713 17:43:18.594724 140353320949632 run_pretraining.py:483] ***** Eval results *****\n",
            "I0713 17:43:18.594840 140353320949632 run_pretraining.py:485]   global_step = 10000\n",
            "I0713 17:43:18.595148 140353320949632 run_pretraining.py:485]   loss = 3.7114496\n",
            "I0713 17:43:18.595254 140353320949632 run_pretraining.py:485]   masked_lm_accuracy = 0.5033093\n",
            "I0713 17:43:18.595330 140353320949632 run_pretraining.py:485]   masked_lm_loss = 3.4754658\n",
            "I0713 17:43:18.595392 140353320949632 run_pretraining.py:485]   next_sentence_accuracy = 0.89375\n",
            "I0713 17:43:18.595462 140353320949632 run_pretraining.py:485]   next_sentence_loss = 0.2630788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXji7dilbTDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fe30540e-df54-4543-bc1b-069836067b8f"
      },
      "source": [
        "# jarraitu pre-training\n",
        "\n",
        "!python bert/run_pretraining.py \\\n",
        "  --input_file={files} \\\n",
        "  --output_dir={OUTPUT_GCS} \\\n",
        "  --do_train=True \\\n",
        "  --do_eval=True \\\n",
        "  --bert_config_file=bert_config.json \\\n",
        "  --train_batch_size=64 \\\n",
        "  --max_seq_length={MAX_SEQ_LEN} \\\n",
        "  --max_predictions_per_seq={MAX_PREDICTIONS_PER_SEQ} \\\n",
        "  --num_train_steps=250000 \\\n",
        "  --num_warmup_steps=10000 \\\n",
        "  --save_checkpoints_steps=10000 \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --use_tpu=True \\\n",
        "  --tpu_name={TPU_ADDRESS} \\\n",
        "  --init_checkpoint={OUTPUT_GCS} \\\n",
        "  #--num_train_steps=1000000 \\\n",
        "  "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0713 22:24:14.442707 140417550112640 deprecation_wrapper.py:119] From /content/gureBERT/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0713 22:24:14.443955 140417550112640 deprecation_wrapper.py:119] From bert/run_pretraining.py:493: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0713 22:24:14.444674 140417550112640 deprecation_wrapper.py:119] From bert/run_pretraining.py:407: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0713 22:24:14.444829 140417550112640 deprecation_wrapper.py:119] From bert/run_pretraining.py:407: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0713 22:24:14.444988 140417550112640 deprecation_wrapper.py:119] From /content/gureBERT/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0713 22:24:14.445811 140417550112640 deprecation_wrapper.py:119] From bert/run_pretraining.py:414: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0713 22:24:15.809234 140417550112640 deprecation_wrapper.py:119] From bert/run_pretraining.py:418: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0713 22:25:32.825901 140417550112640 deprecation_wrapper.py:119] From bert/run_pretraining.py:420: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "I0713 22:25:32.826190 140417550112640 run_pretraining.py:420] *** Input Files ***\n",
            "I0713 22:25:32.826284 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_00.sent_splited.tfrecord\n",
            "I0713 22:25:32.826357 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_01.sent_splited.tfrecord\n",
            "I0713 22:25:32.826427 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_02.sent_splited.tfrecord\n",
            "I0713 22:25:32.826500 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_03.sent_splited.tfrecord\n",
            "I0713 22:25:32.826567 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_04.sent_splited.tfrecord\n",
            "I0713 22:25:32.826653 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_05.sent_splited.tfrecord\n",
            "I0713 22:25:32.826720 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_06.sent_splited.tfrecord\n",
            "I0713 22:25:32.826783 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_07.sent_splited.tfrecord\n",
            "I0713 22:25:32.826851 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_08.sent_splited.tfrecord\n",
            "I0713 22:25:32.826915 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_09.sent_splited.tfrecord\n",
            "I0713 22:25:32.826977 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_10.sent_splited.tfrecord\n",
            "I0713 22:25:32.827041 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_11.sent_splited.tfrecord\n",
            "I0713 22:25:32.827103 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_12.sent_splited.tfrecord\n",
            "I0713 22:25:32.827164 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_13.sent_splited.tfrecord\n",
            "I0713 22:25:32.827226 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_14.sent_splited.tfrecord\n",
            "I0713 22:25:32.827289 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_15.sent_splited.tfrecord\n",
            "I0713 22:25:32.827351 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_16.sent_splited.tfrecord\n",
            "I0713 22:25:32.827413 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_17.sent_splited.tfrecord\n",
            "I0713 22:25:32.827473 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_18.sent_splited.tfrecord\n",
            "I0713 22:25:32.827534 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_19.sent_splited.tfrecord\n",
            "I0713 22:25:32.827609 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_20.sent_splited.tfrecord\n",
            "I0713 22:25:32.827672 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_21.sent_splited.tfrecord\n",
            "I0713 22:25:32.827734 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_22.sent_splited.tfrecord\n",
            "I0713 22:25:32.827790 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_23.sent_splited.tfrecord\n",
            "I0713 22:25:32.827845 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_24.sent_splited.tfrecord\n",
            "I0713 22:25:32.827894 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_25.sent_splited.tfrecord\n",
            "I0713 22:25:32.827942 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_26.sent_splited.tfrecord\n",
            "I0713 22:25:32.827991 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_27.sent_splited.tfrecord\n",
            "I0713 22:25:32.828040 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_28.sent_splited.tfrecord\n",
            "I0713 22:25:32.828099 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_29.sent_splited.tfrecord\n",
            "I0713 22:25:32.828165 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_30.sent_splited.tfrecord\n",
            "I0713 22:25:32.828227 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_31.sent_splited.tfrecord\n",
            "I0713 22:25:32.828289 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_32.sent_splited.tfrecord\n",
            "I0713 22:25:32.828351 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_33.sent_splited.tfrecord\n",
            "I0713 22:25:32.828414 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_34.sent_splited.tfrecord\n",
            "I0713 22:25:32.828476 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_35.sent_splited.tfrecord\n",
            "I0713 22:25:32.828538 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_36.sent_splited.tfrecord\n",
            "I0713 22:25:32.828614 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_37.sent_splited.tfrecord\n",
            "I0713 22:25:32.828677 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_38.sent_splited.tfrecord\n",
            "I0713 22:25:32.828738 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_39.sent_splited.tfrecord\n",
            "I0713 22:25:32.828802 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_40.sent_splited.tfrecord\n",
            "I0713 22:25:32.828869 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_41.sent_splited.tfrecord\n",
            "I0713 22:25:32.828929 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_42.sent_splited.tfrecord\n",
            "I0713 22:25:32.828989 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_43.sent_splited.tfrecord\n",
            "I0713 22:25:32.829052 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_44.sent_splited.tfrecord\n",
            "I0713 22:25:32.829112 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_45.sent_splited.tfrecord\n",
            "I0713 22:25:32.829175 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_46.sent_splited.tfrecord\n",
            "I0713 22:25:32.829234 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_47.sent_splited.tfrecord\n",
            "I0713 22:25:32.829296 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_48.sent_splited.tfrecord\n",
            "I0713 22:25:32.829358 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_49.sent_splited.tfrecord\n",
            "I0713 22:25:32.829418 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_50.sent_splited.tfrecord\n",
            "I0713 22:25:32.829478 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_51.sent_splited.tfrecord\n",
            "I0713 22:25:32.829539 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_52.sent_splited.tfrecord\n",
            "I0713 22:25:32.829610 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_53.sent_splited.tfrecord\n",
            "I0713 22:25:32.829674 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_54.sent_splited.tfrecord\n",
            "I0713 22:25:32.829735 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_55.sent_splited.tfrecord\n",
            "I0713 22:25:32.829797 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_56.sent_splited.tfrecord\n",
            "I0713 22:25:32.829865 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_57.sent_splited.tfrecord\n",
            "I0713 22:25:32.829926 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_58.sent_splited.tfrecord\n",
            "I0713 22:25:32.829989 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_59.sent_splited.tfrecord\n",
            "I0713 22:25:32.830049 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_60.sent_splited.tfrecord\n",
            "I0713 22:25:32.830115 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_61.sent_splited.tfrecord\n",
            "I0713 22:25:32.830180 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_62.sent_splited.tfrecord\n",
            "I0713 22:25:32.830242 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_63.sent_splited.tfrecord\n",
            "I0713 22:25:32.830303 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_64.sent_splited.tfrecord\n",
            "I0713 22:25:32.830366 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_65.sent_splited.tfrecord\n",
            "I0713 22:25:32.830428 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_66.sent_splited.tfrecord\n",
            "I0713 22:25:32.830488 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_67.sent_splited.tfrecord\n",
            "I0713 22:25:32.830550 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_68.sent_splited.tfrecord\n",
            "I0713 22:25:32.830630 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_69.sent_splited.tfrecord\n",
            "I0713 22:25:32.830693 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_70.sent_splited.tfrecord\n",
            "I0713 22:25:32.830756 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_71.sent_splited.tfrecord\n",
            "I0713 22:25:32.830818 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_72.sent_splited.tfrecord\n",
            "I0713 22:25:32.830888 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_73.sent_splited.tfrecord\n",
            "I0713 22:25:32.830949 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_74.sent_splited.tfrecord\n",
            "I0713 22:25:32.831011 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_75.sent_splited.tfrecord\n",
            "I0713 22:25:32.831072 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_76.sent_splited.tfrecord\n",
            "I0713 22:25:32.831134 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_77.sent_splited.tfrecord\n",
            "I0713 22:25:32.831197 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_78.sent_splited.tfrecord\n",
            "I0713 22:25:32.831259 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_79.sent_splited.tfrecord\n",
            "I0713 22:25:32.831321 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_80.sent_splited.tfrecord\n",
            "I0713 22:25:32.831384 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_81.sent_splited.tfrecord\n",
            "I0713 22:25:32.831446 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_82.sent_splited.tfrecord\n",
            "I0713 22:25:32.831508 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_83.sent_splited.tfrecord\n",
            "I0713 22:25:32.831569 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_84.sent_splited.tfrecord\n",
            "I0713 22:25:32.831646 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_85.sent_splited.tfrecord\n",
            "I0713 22:25:32.831707 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_86.sent_splited.tfrecord\n",
            "I0713 22:25:32.831769 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_87.sent_splited.tfrecord\n",
            "I0713 22:25:32.831837 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_88.sent_splited.tfrecord\n",
            "I0713 22:25:32.831900 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_89.sent_splited.tfrecord\n",
            "I0713 22:25:32.831961 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_90.sent_splited.tfrecord\n",
            "I0713 22:25:32.832027 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_91.sent_splited.tfrecord\n",
            "I0713 22:25:32.832092 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_92.sent_splited.tfrecord\n",
            "I0713 22:25:32.832153 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_93.sent_splited.tfrecord\n",
            "I0713 22:25:32.832215 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_94.sent_splited.tfrecord\n",
            "I0713 22:25:32.832277 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_95.sent_splited.tfrecord\n",
            "I0713 22:25:32.832338 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_96.sent_splited.tfrecord\n",
            "I0713 22:25:32.832399 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_97.sent_splited.tfrecord\n",
            "I0713 22:25:32.832460 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_98.sent_splited.tfrecord\n",
            "I0713 22:25:32.832523 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AA/wiki_99.sent_splited.tfrecord\n",
            "I0713 22:25:32.832598 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_00.sent_splited.tfrecord\n",
            "I0713 22:25:32.832665 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_01.sent_splited.tfrecord\n",
            "I0713 22:25:32.832737 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_02.sent_splited.tfrecord\n",
            "I0713 22:25:32.832810 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_03.sent_splited.tfrecord\n",
            "I0713 22:25:32.832881 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_04.sent_splited.tfrecord\n",
            "I0713 22:25:32.832943 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_05.sent_splited.tfrecord\n",
            "I0713 22:25:32.833006 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_06.sent_splited.tfrecord\n",
            "I0713 22:25:32.833067 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_07.sent_splited.tfrecord\n",
            "I0713 22:25:32.833128 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_08.sent_splited.tfrecord\n",
            "I0713 22:25:32.833192 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_09.sent_splited.tfrecord\n",
            "I0713 22:25:32.833254 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_10.sent_splited.tfrecord\n",
            "I0713 22:25:32.833316 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_11.sent_splited.tfrecord\n",
            "I0713 22:25:32.833382 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_12.sent_splited.tfrecord\n",
            "I0713 22:25:32.833444 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_13.sent_splited.tfrecord\n",
            "I0713 22:25:32.833506 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_14.sent_splited.tfrecord\n",
            "I0713 22:25:32.833567 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_15.sent_splited.tfrecord\n",
            "I0713 22:25:32.833643 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_16.sent_splited.tfrecord\n",
            "I0713 22:25:32.833704 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_17.sent_splited.tfrecord\n",
            "I0713 22:25:32.833765 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_18.sent_splited.tfrecord\n",
            "I0713 22:25:32.833832 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_19.sent_splited.tfrecord\n",
            "I0713 22:25:32.833895 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_20.sent_splited.tfrecord\n",
            "I0713 22:25:32.833959 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_21.sent_splited.tfrecord\n",
            "I0713 22:25:32.898637 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_22.sent_splited.tfrecord\n",
            "I0713 22:25:32.899177 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_23.sent_splited.tfrecord\n",
            "I0713 22:25:32.899295 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_24.sent_splited.tfrecord\n",
            "I0713 22:25:32.899399 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_25.sent_splited.tfrecord\n",
            "I0713 22:25:32.899502 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_26.sent_splited.tfrecord\n",
            "I0713 22:25:32.899606 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_27.sent_splited.tfrecord\n",
            "I0713 22:25:32.899879 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_28.sent_splited.tfrecord\n",
            "I0713 22:25:32.900001 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_29.sent_splited.tfrecord\n",
            "I0713 22:25:32.900078 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_30.sent_splited.tfrecord\n",
            "I0713 22:25:32.900167 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_31.sent_splited.tfrecord\n",
            "I0713 22:25:32.900398 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_32.sent_splited.tfrecord\n",
            "I0713 22:25:32.900485 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_33.sent_splited.tfrecord\n",
            "I0713 22:25:32.900560 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_34.sent_splited.tfrecord\n",
            "I0713 22:25:32.900774 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_35.sent_splited.tfrecord\n",
            "I0713 22:25:32.900959 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_36.sent_splited.tfrecord\n",
            "I0713 22:25:32.901183 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_37.sent_splited.tfrecord\n",
            "I0713 22:25:32.901303 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_38.sent_splited.tfrecord\n",
            "I0713 22:25:32.901386 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_39.sent_splited.tfrecord\n",
            "I0713 22:25:32.901460 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_40.sent_splited.tfrecord\n",
            "I0713 22:25:32.901683 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_41.sent_splited.tfrecord\n",
            "I0713 22:25:32.901780 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_42.sent_splited.tfrecord\n",
            "I0713 22:25:32.901869 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_43.sent_splited.tfrecord\n",
            "I0713 22:25:32.902070 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_44.sent_splited.tfrecord\n",
            "I0713 22:25:32.902165 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_45.sent_splited.tfrecord\n",
            "I0713 22:25:32.902243 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_46.sent_splited.tfrecord\n",
            "I0713 22:25:32.902332 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_47.sent_splited.tfrecord\n",
            "I0713 22:25:32.902532 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_48.sent_splited.tfrecord\n",
            "I0713 22:25:32.902636 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_49.sent_splited.tfrecord\n",
            "I0713 22:25:32.902729 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_50.sent_splited.tfrecord\n",
            "I0713 22:25:32.902939 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_51.sent_splited.tfrecord\n",
            "I0713 22:25:32.903022 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_52.sent_splited.tfrecord\n",
            "I0713 22:25:32.903096 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_53.sent_splited.tfrecord\n",
            "I0713 22:25:32.903301 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_54.sent_splited.tfrecord\n",
            "I0713 22:25:32.903391 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_55.sent_splited.tfrecord\n",
            "I0713 22:25:32.903467 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_56.sent_splited.tfrecord\n",
            "I0713 22:25:32.903685 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_57.sent_splited.tfrecord\n",
            "I0713 22:25:32.903790 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_58.sent_splited.tfrecord\n",
            "I0713 22:25:32.903883 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_59.sent_splited.tfrecord\n",
            "I0713 22:25:32.904082 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_60.sent_splited.tfrecord\n",
            "I0713 22:25:32.904178 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_61.sent_splited.tfrecord\n",
            "I0713 22:25:32.904255 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_62.sent_splited.tfrecord\n",
            "I0713 22:25:32.904347 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_63.sent_splited.tfrecord\n",
            "I0713 22:25:32.904548 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_64.sent_splited.tfrecord\n",
            "I0713 22:25:32.904655 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_65.sent_splited.tfrecord\n",
            "I0713 22:25:32.904746 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_66.sent_splited.tfrecord\n",
            "I0713 22:25:32.904957 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_67.sent_splited.tfrecord\n",
            "I0713 22:25:32.905041 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_68.sent_splited.tfrecord\n",
            "I0713 22:25:32.905116 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_69.sent_splited.tfrecord\n",
            "I0713 22:25:32.905319 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_70.sent_splited.tfrecord\n",
            "I0713 22:25:32.905407 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_71.sent_splited.tfrecord\n",
            "I0713 22:25:32.905483 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_72.sent_splited.tfrecord\n",
            "I0713 22:25:32.905694 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_73.sent_splited.tfrecord\n",
            "I0713 22:25:32.905795 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_74.sent_splited.tfrecord\n",
            "I0713 22:25:32.905887 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_75.sent_splited.tfrecord\n",
            "I0713 22:25:32.906075 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_76.sent_splited.tfrecord\n",
            "I0713 22:25:32.906184 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_77.sent_splited.tfrecord\n",
            "I0713 22:25:32.906273 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_78.sent_splited.tfrecord\n",
            "I0713 22:25:32.906357 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_79.sent_splited.tfrecord\n",
            "I0713 22:25:32.906570 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_80.sent_splited.tfrecord\n",
            "I0713 22:25:32.906684 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_81.sent_splited.tfrecord\n",
            "I0713 22:25:32.906772 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_82.sent_splited.tfrecord\n",
            "I0713 22:25:32.906995 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_83.sent_splited.tfrecord\n",
            "I0713 22:25:32.907088 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_84.sent_splited.tfrecord\n",
            "I0713 22:25:32.907173 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_85.sent_splited.tfrecord\n",
            "I0713 22:25:32.907388 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_86.sent_splited.tfrecord\n",
            "I0713 22:25:32.907479 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_87.sent_splited.tfrecord\n",
            "I0713 22:25:32.907565 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_88.sent_splited.tfrecord\n",
            "I0713 22:25:32.907792 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_89.sent_splited.tfrecord\n",
            "I0713 22:25:32.907899 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_90.sent_splited.tfrecord\n",
            "I0713 22:25:32.907986 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_91.sent_splited.tfrecord\n",
            "I0713 22:25:32.908193 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_92.sent_splited.tfrecord\n",
            "I0713 22:25:32.908288 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_93.sent_splited.tfrecord\n",
            "I0713 22:25:32.908374 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_94.sent_splited.tfrecord\n",
            "I0713 22:25:32.908606 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_95.sent_splited.tfrecord\n",
            "I0713 22:25:32.908709 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_96.sent_splited.tfrecord\n",
            "I0713 22:25:32.908797 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_97.sent_splited.tfrecord\n",
            "I0713 22:25:32.909011 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_98.sent_splited.tfrecord\n",
            "I0713 22:25:32.909115 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AB/wiki_99.sent_splited.tfrecord\n",
            "I0713 22:25:32.909203 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_00.sent_splited.tfrecord\n",
            "I0713 22:25:32.909417 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_01.sent_splited.tfrecord\n",
            "I0713 22:25:32.909518 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_02.sent_splited.tfrecord\n",
            "I0713 22:25:32.909622 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_03.sent_splited.tfrecord\n",
            "I0713 22:25:32.909839 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_04.sent_splited.tfrecord\n",
            "I0713 22:25:32.909945 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_05.sent_splited.tfrecord\n",
            "I0713 22:25:32.910033 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_06.sent_splited.tfrecord\n",
            "I0713 22:25:32.910247 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_07.sent_splited.tfrecord\n",
            "I0713 22:25:32.910347 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_08.sent_splited.tfrecord\n",
            "I0713 22:25:32.910434 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_09.sent_splited.tfrecord\n",
            "I0713 22:25:32.910654 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_10.sent_splited.tfrecord\n",
            "I0713 22:25:32.910760 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_11.sent_splited.tfrecord\n",
            "I0713 22:25:32.910858 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_12.sent_splited.tfrecord\n",
            "I0713 22:25:32.911062 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_13.sent_splited.tfrecord\n",
            "I0713 22:25:32.911167 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_14.sent_splited.tfrecord\n",
            "I0713 22:25:32.911255 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_15.sent_splited.tfrecord\n",
            "I0713 22:25:32.911453 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_16.sent_splited.tfrecord\n",
            "I0713 22:25:32.911561 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_17.sent_splited.tfrecord\n",
            "I0713 22:25:32.911669 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_18.sent_splited.tfrecord\n",
            "I0713 22:25:32.911885 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_19.sent_splited.tfrecord\n",
            "I0713 22:25:32.911994 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_20.sent_splited.tfrecord\n",
            "I0713 22:25:32.912082 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_21.sent_splited.tfrecord\n",
            "I0713 22:25:32.912287 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_22.sent_splited.tfrecord\n",
            "I0713 22:25:32.912394 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_23.sent_splited.tfrecord\n",
            "I0713 22:25:32.912481 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_24.sent_splited.tfrecord\n",
            "I0713 22:25:32.912693 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_25.sent_splited.tfrecord\n",
            "I0713 22:25:32.912797 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_26.sent_splited.tfrecord\n",
            "I0713 22:25:32.912897 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_27.sent_splited.tfrecord\n",
            "I0713 22:25:32.913089 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_28.sent_splited.tfrecord\n",
            "I0713 22:25:32.913189 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_29.sent_splited.tfrecord\n",
            "I0713 22:25:32.913276 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_30.sent_splited.tfrecord\n",
            "I0713 22:25:32.913360 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_31.sent_splited.tfrecord\n",
            "I0713 22:25:32.913572 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_32.sent_splited.tfrecord\n",
            "I0713 22:25:32.913683 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_33.sent_splited.tfrecord\n",
            "I0713 22:25:32.913769 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_34.sent_splited.tfrecord\n",
            "I0713 22:25:32.913994 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_35.sent_splited.tfrecord\n",
            "I0713 22:25:32.914084 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_36.sent_splited.tfrecord\n",
            "I0713 22:25:32.914170 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_37.sent_splited.tfrecord\n",
            "I0713 22:25:32.914379 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_38.sent_splited.tfrecord\n",
            "I0713 22:25:32.914474 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_39.sent_splited.tfrecord\n",
            "I0713 22:25:32.914560 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_40.sent_splited.tfrecord\n",
            "I0713 22:25:32.914782 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_41.sent_splited.tfrecord\n",
            "I0713 22:25:32.914898 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_42.sent_splited.tfrecord\n",
            "I0713 22:25:32.914988 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_43.sent_splited.tfrecord\n",
            "I0713 22:25:32.915202 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_44.sent_splited.tfrecord\n",
            "I0713 22:25:32.915302 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_45.sent_splited.tfrecord\n",
            "I0713 22:25:32.915390 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_46.sent_splited.tfrecord\n",
            "I0713 22:25:32.915605 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_47.sent_splited.tfrecord\n",
            "I0713 22:25:32.915710 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_48.sent_splited.tfrecord\n",
            "I0713 22:25:32.915797 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_49.sent_splited.tfrecord\n",
            "I0713 22:25:32.916028 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_50.sent_splited.tfrecord\n",
            "I0713 22:25:32.916134 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_51.sent_splited.tfrecord\n",
            "I0713 22:25:32.916221 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_52.sent_splited.tfrecord\n",
            "I0713 22:25:32.916418 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_53.sent_splited.tfrecord\n",
            "I0713 22:25:32.916520 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_54.sent_splited.tfrecord\n",
            "I0713 22:25:32.916623 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_55.sent_splited.tfrecord\n",
            "I0713 22:25:32.916830 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_56.sent_splited.tfrecord\n",
            "I0713 22:25:32.916933 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_57.sent_splited.tfrecord\n",
            "I0713 22:25:32.917019 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_58.sent_splited.tfrecord\n",
            "I0713 22:25:32.917211 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_59.sent_splited.tfrecord\n",
            "I0713 22:25:32.917310 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_60.sent_splited.tfrecord\n",
            "I0713 22:25:32.917396 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_61.sent_splited.tfrecord\n",
            "I0713 22:25:32.917479 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_62.sent_splited.tfrecord\n",
            "I0713 22:25:32.917708 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_63.sent_splited.tfrecord\n",
            "I0713 22:25:32.917803 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_64.sent_splited.tfrecord\n",
            "I0713 22:25:32.917899 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_65.sent_splited.tfrecord\n",
            "I0713 22:25:32.918113 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_66.sent_splited.tfrecord\n",
            "I0713 22:25:32.918205 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_67.sent_splited.tfrecord\n",
            "I0713 22:25:32.918289 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_68.sent_splited.tfrecord\n",
            "I0713 22:25:32.918505 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_69.sent_splited.tfrecord\n",
            "I0713 22:25:32.918616 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_70.sent_splited.tfrecord\n",
            "I0713 22:25:32.918705 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_71.sent_splited.tfrecord\n",
            "I0713 22:25:32.918927 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_72.sent_splited.tfrecord\n",
            "I0713 22:25:32.919035 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_73.sent_splited.tfrecord\n",
            "I0713 22:25:32.919136 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_74.sent_splited.tfrecord\n",
            "I0713 22:25:32.919337 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_75.sent_splited.tfrecord\n",
            "I0713 22:25:32.919429 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_76.sent_splited.tfrecord\n",
            "I0713 22:25:32.919514 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_77.sent_splited.tfrecord\n",
            "I0713 22:25:32.919744 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_78.sent_splited.tfrecord\n",
            "I0713 22:25:32.919847 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_79.sent_splited.tfrecord\n",
            "I0713 22:25:32.919938 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_80.sent_splited.tfrecord\n",
            "I0713 22:25:32.920152 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_81.sent_splited.tfrecord\n",
            "I0713 22:25:32.920266 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_82.sent_splited.tfrecord\n",
            "I0713 22:25:32.920356 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_83.sent_splited.tfrecord\n",
            "I0713 22:25:32.920564 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_84.sent_splited.tfrecord\n",
            "I0713 22:25:32.920680 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_85.sent_splited.tfrecord\n",
            "I0713 22:25:32.920768 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_86.sent_splited.tfrecord\n",
            "I0713 22:25:32.920987 140417550112640 run_pretraining.py:422]   gs://gurebert/gureBERT/corpus/eu/AC/wiki_87.sent_splited.tfrecord\n",
            "W0713 22:25:33.981275 140417550112640 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0713 22:25:34.987198 140417550112640 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fb54c36a9d8>) includes params argument, but params are not passed to Estimator.\n",
            "I0713 22:25:34.988931 140417550112640 estimator.py:209] Using config: {'_model_dir': 'gs://gurebert/gureBERT/wordpiece/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.51.131.226:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb5585bf588>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.51.131.226:8470', '_evaluation_master': 'grpc://10.51.131.226:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7fb5585c82b0>}\n",
            "I0713 22:25:34.989261 140417550112640 tpu_context.py:209] _TPUContext: eval_on_tpu True\n",
            "I0713 22:25:34.989979 140417550112640 run_pretraining.py:459] ***** Running training *****\n",
            "I0713 22:25:34.990076 140417550112640 run_pretraining.py:460]   Batch size = 64\n",
            "I0713 22:25:37.284889 140417550112640 tpu_system_metadata.py:78] Querying Tensorflow master (grpc://10.51.131.226:8470) for TPU system metadata.\n",
            "2019-07-13 22:25:37.286425: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:356] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
            "I0713 22:25:37.301140 140417550112640 tpu_system_metadata.py:148] Found TPU system:\n",
            "I0713 22:25:37.301450 140417550112640 tpu_system_metadata.py:149] *** Num TPU Cores: 8\n",
            "I0713 22:25:37.301555 140417550112640 tpu_system_metadata.py:150] *** Num TPU Workers: 1\n",
            "I0713 22:25:37.301660 140417550112640 tpu_system_metadata.py:152] *** Num TPU Cores Per Worker: 8\n",
            "I0713 22:25:37.301730 140417550112640 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 6810479753173132532)\n",
            "I0713 22:25:37.302566 140417550112640 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 14433261477188369500)\n",
            "I0713 22:25:37.302671 140417550112640 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 10471305944331051035)\n",
            "I0713 22:25:37.302757 140417550112640 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 290337485020010624)\n",
            "I0713 22:25:37.302828 140417550112640 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 8844700230351949478)\n",
            "I0713 22:25:37.302894 140417550112640 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 17633311837389007867)\n",
            "I0713 22:25:37.302956 140417550112640 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 501559178114276546)\n",
            "I0713 22:25:37.303017 140417550112640 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 7430056111459679944)\n",
            "I0713 22:25:37.303078 140417550112640 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 13593346917957416754)\n",
            "I0713 22:25:37.303138 140417550112640 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 11162654302255930259)\n",
            "I0713 22:25:37.303200 140417550112640 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 9581148650088822417)\n",
            "W0713 22:25:37.309870 140417550112640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "I0713 22:25:37.323917 140417550112640 estimator.py:1145] Calling model_fn.\n",
            "W0713 22:25:37.324595 140417550112640 deprecation_wrapper.py:119] From bert/run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0713 22:25:37.331922 140417550112640 deprecation.py:323] From bert/run_pretraining.py:368: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0713 22:25:37.332148 140417550112640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0713 22:25:37.361214 140417550112640 deprecation.py:323] From bert/run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "W0713 22:25:37.361489 140417550112640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W0713 22:25:37.363206 140417550112640 deprecation_wrapper.py:119] From bert/run_pretraining.py:393: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0713 22:25:37.369064 140417550112640 deprecation.py:323] From bert/run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "I0713 22:25:37.464797 140417550112640 run_pretraining.py:117] *** Features ***\n",
            "I0713 22:25:37.465121 140417550112640 run_pretraining.py:119]   name = input_ids, shape = (8, 128)\n",
            "I0713 22:25:37.465268 140417550112640 run_pretraining.py:119]   name = input_mask, shape = (8, 128)\n",
            "I0713 22:25:37.465382 140417550112640 run_pretraining.py:119]   name = masked_lm_ids, shape = (8, 19)\n",
            "I0713 22:25:37.465491 140417550112640 run_pretraining.py:119]   name = masked_lm_positions, shape = (8, 19)\n",
            "I0713 22:25:37.465613 140417550112640 run_pretraining.py:119]   name = masked_lm_weights, shape = (8, 19)\n",
            "I0713 22:25:37.465710 140417550112640 run_pretraining.py:119]   name = next_sentence_labels, shape = (8, 1)\n",
            "I0713 22:25:37.465808 140417550112640 run_pretraining.py:119]   name = segment_ids, shape = (8, 128)\n",
            "W0713 22:25:37.466110 140417550112640 deprecation_wrapper.py:119] From /content/gureBERT/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0713 22:25:37.469521 140417550112640 deprecation_wrapper.py:119] From /content/gureBERT/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0713 22:25:37.514071 140417550112640 deprecation_wrapper.py:119] From /content/gureBERT/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "W0713 22:25:37.700309 140417550112640 deprecation.py:506] From /content/gureBERT/bert/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0713 22:25:37.723338 140417550112640 deprecation.py:323] From /content/gureBERT/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "I0713 22:25:42.588656 140417550112640 run_pretraining.py:167] **** Trainable Variables ****\n",
            "I0713 22:25:42.588951 140417550112640 run_pretraining.py:173]   name = bert/embeddings/word_embeddings:0, shape = (32000, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.589087 140417550112640 run_pretraining.py:173]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.589185 140417550112640 run_pretraining.py:173]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.589280 140417550112640 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.589366 140417550112640 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.589448 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.589531 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.589623 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.589704 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.589778 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.589855 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.589935 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.590013 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.590088 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.590162 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.590234 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.590319 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.590392 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.590469 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.590543 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.590632 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.590709 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.590789 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.590863 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.590941 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.591016 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.591094 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.591167 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.591256 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.591335 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.591408 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.591482 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.591566 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.591660 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.591739 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.591815 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.591888 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.591962 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.592040 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.592121 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.592199 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.592281 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.592361 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.592436 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.592519 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.592612 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.592706 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.592793 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.592876 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.592952 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.593030 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.593105 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.593180 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.593262 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.593342 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.593417 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.593498 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.593591 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.593675 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.593751 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.593831 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.593906 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.593982 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.594057 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.594136 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.594211 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.594296 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.594372 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.594446 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.594521 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.594612 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.594687 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.594767 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.594844 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.594923 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.594997 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.595076 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.595151 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.595225 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.595309 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.595388 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.595463 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.595540 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.595628 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.595703 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.595777 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.595856 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.595930 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.596075 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.596204 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.596297 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.596374 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.596452 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.596535 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.596624 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.596699 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.596778 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.596854 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.596932 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.597007 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.597082 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.597163 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.597251 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.597327 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.597405 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.597481 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.597559 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.597649 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.597730 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.597808 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.597882 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.597958 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.598036 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.598111 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.598217 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.598307 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.598381 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.598456 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.598534 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.598621 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.598703 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.599864 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.600030 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.600134 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.600262 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.600362 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.600453 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.600546 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.600673 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.600778 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.600887 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.601006 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.601109 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.601208 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.601425 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.601565 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.601712 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.601826 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.601938 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.602045 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.602155 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.602275 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.602386 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.602492 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.602624 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.602738 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.602854 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.602960 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.603063 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.603168 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.603291 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.603398 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.603508 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.603636 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.603750 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.603858 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.603968 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.604073 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.604174 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.604285 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.604398 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.604504 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.604629 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.604740 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.604847 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.604956 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.605070 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.605175 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.605296 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.605404 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.605515 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.605642 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.605755 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.605860 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.605965 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.606067 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.606178 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.606297 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.606412 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.606517 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.606640 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.606749 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.606861 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.606968 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.607080 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.607187 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.607308 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.607418 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.607529 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.607653 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.607761 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.607868 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.607979 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.608083 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.608194 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.608313 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.608417 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.608523 140417550112640 run_pretraining.py:173]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.608656 140417550112640 run_pretraining.py:173]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.608789 140417550112640 run_pretraining.py:173]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.608917 140417550112640 run_pretraining.py:173]   name = cls/predictions/transform/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.609025 140417550112640 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.609129 140417550112640 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.609230 140417550112640 run_pretraining.py:173]   name = cls/predictions/output_bias:0, shape = (32000,), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.609349 140417550112640 run_pretraining.py:173]   name = cls/seq_relationship/output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "I0713 22:25:42.609461 140417550112640 run_pretraining.py:173]   name = cls/seq_relationship/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
            "W0713 22:25:42.609683 140417550112640 deprecation_wrapper.py:119] From /content/gureBERT/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0713 22:25:42.611527 140417550112640 deprecation_wrapper.py:119] From /content/gureBERT/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "W0713 22:25:42.619595 140417550112640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0713 22:25:42.912023 140417550112640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0713 22:25:56.272084 140417550112640 deprecation_wrapper.py:119] From bert/run_pretraining.py:160: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W0713 22:25:58.369364 140417550112640 deprecation_wrapper.py:119] From bert/run_pretraining.py:161: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "I0713 22:25:59.384390 140417550112640 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "I0713 22:25:59.791135 140417550112640 estimator.py:1147] Done calling model_fn.\n",
            "I0713 22:26:04.133620 140417550112640 tpu_estimator.py:499] TPU job name worker\n",
            "I0713 22:26:05.898219 140417550112640 monitored_session.py:240] Graph was finalized.\n",
            "W0713 22:26:06.046355 140417550112640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "I0713 22:26:06.204059 140417550112640 saver.py:1280] Restoring parameters from gs://gurebert/gureBERT/wordpiece/model/model.ckpt-200000\n",
            "W0713 22:26:37.626762 140417550112640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "I0713 22:26:40.576091 140417550112640 session_manager.py:500] Running local_init_op.\n",
            "I0713 22:26:41.837508 140417550112640 session_manager.py:502] Done running local_init_op.\n",
            "I0713 22:26:55.183796 140417550112640 basic_session_run_hooks.py:606] Saving checkpoints for 200000 into gs://gurebert/gureBERT/wordpiece/model/model.ckpt.\n",
            "W0713 22:27:22.717418 140417550112640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:741: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "I0713 22:27:25.119487 140417550112640 util.py:98] Initialized dataset iterators in 1 seconds\n",
            "I0713 22:27:25.120800 140417550112640 session_support.py:332] Installing graceful shutdown hook.\n",
            "2019-07-13 22:27:25.121233: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:356] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
            "I0713 22:27:25.126923 140417550112640 session_support.py:82] Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "I0713 22:27:25.129159 140417550112640 session_support.py:105] Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "I0713 22:27:25.133413 140417550112640 tpu_estimator.py:557] Init TPU system\n",
            "I0713 22:27:30.481683 140417550112640 tpu_estimator.py:566] Initialized TPU in 5 seconds\n",
            "I0713 22:27:30.482614 140416392439552 tpu_estimator.py:514] Starting infeed thread controller.\n",
            "I0713 22:27:30.482965 140416363865856 tpu_estimator.py:533] Starting outfeed thread controller.\n",
            "I0713 22:27:31.744042 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:27:31.745175 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:28:10.337390 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (0, 0)\n",
            "I0713 22:29:10.348919 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (0, 938)\n",
            "I0713 22:29:15.937626 140417550112640 basic_session_run_hooks.py:262] loss = 2.5854335, step = 201000\n",
            "I0713 22:29:15.941029 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:29:15.941384 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:30:10.379734 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (1, 687)\n",
            "I0713 22:30:31.110108 140417550112640 basic_session_run_hooks.py:260] loss = 1.9556884, step = 202000 (75.173 sec)\n",
            "I0713 22:30:31.111867 140417550112640 tpu_estimator.py:2159] global_step/sec: 13.3028\n",
            "I0713 22:30:31.113000 140417550112640 tpu_estimator.py:2160] examples/sec: 851.38\n",
            "I0713 22:30:31.114565 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:30:31.114853 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:31:10.421719 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (2, 595)\n",
            "I0713 22:31:37.017683 140417550112640 basic_session_run_hooks.py:260] loss = 1.5953635, step = 203000 (65.908 sec)\n",
            "I0713 22:31:37.019298 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1728\n",
            "I0713 22:31:37.019500 140417550112640 tpu_estimator.py:2160] examples/sec: 971.059\n",
            "I0713 22:31:37.903625 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:31:37.903916 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:32:10.483073 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (3, 489)\n",
            "I0713 22:32:43.917001 140417550112640 basic_session_run_hooks.py:260] loss = 1.5862716, step = 204000 (66.899 sec)\n",
            "I0713 22:32:43.918553 140417550112640 tpu_estimator.py:2159] global_step/sec: 14.9478\n",
            "I0713 22:32:43.918763 140417550112640 tpu_estimator.py:2160] examples/sec: 956.661\n",
            "I0713 22:32:43.919849 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:32:43.920031 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:33:10.483428 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (4, 396)\n",
            "I0713 22:33:49.813394 140417550112640 basic_session_run_hooks.py:260] loss = 1.747054, step = 205000 (65.896 sec)\n",
            "I0713 22:33:49.815351 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1753\n",
            "I0713 22:33:49.815608 140417550112640 tpu_estimator.py:2160] examples/sec: 971.217\n",
            "I0713 22:33:50.755968 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:33:50.756992 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:34:10.491807 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (5, 289)\n",
            "I0713 22:34:56.687412 140417550112640 basic_session_run_hooks.py:260] loss = 0.53094524, step = 206000 (66.874 sec)\n",
            "I0713 22:34:56.689360 140417550112640 tpu_estimator.py:2159] global_step/sec: 14.9535\n",
            "I0713 22:34:56.689595 140417550112640 tpu_estimator.py:2160] examples/sec: 957.023\n",
            "I0713 22:34:56.691127 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:34:56.691383 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:35:10.498237 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (6, 196)\n",
            "I0713 22:36:03.505881 140417550112640 basic_session_run_hooks.py:260] loss = 2.2068493, step = 207000 (66.818 sec)\n",
            "I0713 22:36:03.507696 140417550112640 tpu_estimator.py:2159] global_step/sec: 14.966\n",
            "I0713 22:36:03.507930 140417550112640 tpu_estimator.py:2160] examples/sec: 957.822\n",
            "I0713 22:36:03.509330 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:36:03.509611 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:36:10.547108 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (7, 90)\n",
            "I0713 22:37:09.487144 140417550112640 basic_session_run_hooks.py:260] loss = 1.4019496, step = 208000 (65.981 sec)\n",
            "I0713 22:37:09.488991 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1558\n",
            "I0713 22:37:09.489651 140417550112640 tpu_estimator.py:2160] examples/sec: 969.971\n",
            "I0713 22:37:09.491206 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:37:09.491410 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:37:10.727802 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (8, 0)\n",
            "I0713 22:38:10.731205 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (8, 938)\n",
            "I0713 22:38:15.384663 140417550112640 basic_session_run_hooks.py:260] loss = 2.6758301, step = 209000 (65.898 sec)\n",
            "I0713 22:38:15.386529 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1751\n",
            "I0713 22:38:15.386756 140417550112640 tpu_estimator.py:2160] examples/sec: 971.205\n",
            "I0713 22:38:16.320803 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:38:16.321735 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:39:10.759002 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (9, 831)\n",
            "I0713 22:39:22.229786 140417550112640 basic_session_run_hooks.py:606] Saving checkpoints for 210000 into gs://gurebert/gureBERT/wordpiece/model/model.ckpt.\n",
            "W0713 22:39:44.021130 140417550112640 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "I0713 22:39:48.280445 140417550112640 basic_session_run_hooks.py:260] loss = 2.1813643, step = 210000 (92.896 sec)\n",
            "I0713 22:39:48.282232 140417550112640 tpu_estimator.py:2159] global_step/sec: 10.7648\n",
            "I0713 22:39:48.282472 140417550112640 tpu_estimator.py:2160] examples/sec: 688.944\n",
            "I0713 22:39:48.283901 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:39:48.284126 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:40:10.819160 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (10, 332)\n",
            "I0713 22:40:54.242714 140417550112640 basic_session_run_hooks.py:260] loss = 2.019012, step = 211000 (65.962 sec)\n",
            "I0713 22:40:54.244606 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1602\n",
            "I0713 22:40:54.244830 140417550112640 tpu_estimator.py:2160] examples/sec: 970.251\n",
            "I0713 22:40:55.281670 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:40:55.282023 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:41:10.841141 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (11, 223)\n",
            "I0713 22:42:01.315085 140417550112640 basic_session_run_hooks.py:260] loss = 1.3022391, step = 212000 (67.072 sec)\n",
            "I0713 22:42:01.316955 140417550112640 tpu_estimator.py:2159] global_step/sec: 14.9093\n",
            "I0713 22:42:01.317202 140417550112640 tpu_estimator.py:2160] examples/sec: 954.195\n",
            "I0713 22:42:01.318680 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:42:01.318954 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:42:10.904429 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (12, 130)\n",
            "I0713 22:43:08.278994 140417550112640 basic_session_run_hooks.py:260] loss = 0.9232118, step = 213000 (66.964 sec)\n",
            "I0713 22:43:08.281052 140417550112640 tpu_estimator.py:2159] global_step/sec: 14.9334\n",
            "I0713 22:43:08.281297 140417550112640 tpu_estimator.py:2160] examples/sec: 955.735\n",
            "I0713 22:43:08.282904 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:43:08.283145 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:43:10.952990 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (13, 22)\n",
            "I0713 22:44:10.958379 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (13, 960)\n",
            "I0713 22:44:14.241111 140417550112640 basic_session_run_hooks.py:260] loss = 0.87313676, step = 214000 (65.962 sec)\n",
            "I0713 22:44:14.242920 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1603\n",
            "I0713 22:44:14.243110 140417550112640 tpu_estimator.py:2160] examples/sec: 970.257\n",
            "I0713 22:44:14.244846 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:44:14.245053 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:45:10.995301 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (14, 868)\n",
            "I0713 22:45:20.166535 140417550112640 basic_session_run_hooks.py:260] loss = 0.25585666, step = 215000 (65.925 sec)\n",
            "I0713 22:45:20.168505 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1686\n",
            "I0713 22:45:20.168729 140417550112640 tpu_estimator.py:2160] examples/sec: 970.792\n",
            "I0713 22:45:21.107886 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:45:21.108746 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:46:11.001242 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (15, 759)\n",
            "I0713 22:46:27.125220 140417550112640 basic_session_run_hooks.py:260] loss = 0.8710772, step = 216000 (66.959 sec)\n",
            "I0713 22:46:27.127103 140417550112640 tpu_estimator.py:2159] global_step/sec: 14.9346\n",
            "I0713 22:46:27.127316 140417550112640 tpu_estimator.py:2160] examples/sec: 955.814\n",
            "I0713 22:46:27.129017 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:46:27.129268 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:47:11.041260 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (16, 666)\n",
            "I0713 22:47:33.127975 140417550112640 basic_session_run_hooks.py:260] loss = 1.3736742, step = 217000 (66.003 sec)\n",
            "I0713 22:47:33.129773 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1509\n",
            "I0713 22:47:33.129995 140417550112640 tpu_estimator.py:2160] examples/sec: 969.658\n",
            "I0713 22:47:33.958304 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:47:33.958634 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:48:11.059649 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (17, 559)\n",
            "I0713 22:48:40.027089 140417550112640 basic_session_run_hooks.py:260] loss = 1.047138, step = 218000 (66.899 sec)\n",
            "I0713 22:48:40.028732 140417550112640 tpu_estimator.py:2159] global_step/sec: 14.9479\n",
            "I0713 22:48:40.028917 140417550112640 tpu_estimator.py:2160] examples/sec: 956.666\n",
            "I0713 22:48:40.030277 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:48:40.030504 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:49:11.061318 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (18, 465)\n",
            "I0713 22:49:46.988804 140417550112640 basic_session_run_hooks.py:260] loss = 1.5889125, step = 219000 (66.962 sec)\n",
            "I0713 22:49:46.990359 140417550112640 tpu_estimator.py:2159] global_step/sec: 14.9339\n",
            "I0713 22:49:46.990630 140417550112640 tpu_estimator.py:2160] examples/sec: 955.771\n",
            "I0713 22:49:46.991974 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:49:46.992179 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:50:11.118412 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (19, 357)\n",
            "I0713 22:50:52.980348 140417550112640 basic_session_run_hooks.py:606] Saving checkpoints for 220000 into gs://gurebert/gureBERT/wordpiece/model/model.ckpt.\n",
            "I0713 22:51:19.909978 140417550112640 basic_session_run_hooks.py:260] loss = 2.8947265, step = 220000 (92.921 sec)\n",
            "I0713 22:51:19.911802 140417550112640 tpu_estimator.py:2159] global_step/sec: 10.7618\n",
            "I0713 22:51:19.912042 140417550112640 tpu_estimator.py:2160] examples/sec: 688.754\n",
            "I0713 22:51:19.913412 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:51:19.913624 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:51:21.149558 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (20, 0)\n",
            "I0713 22:52:21.162395 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (20, 938)\n",
            "I0713 22:52:25.827230 140417550112640 basic_session_run_hooks.py:260] loss = 1.3487109, step = 221000 (65.917 sec)\n",
            "I0713 22:52:25.829252 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1705\n",
            "I0713 22:52:25.829521 140417550112640 tpu_estimator.py:2160] examples/sec: 970.912\n",
            "I0713 22:52:26.862232 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:52:26.862671 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:53:21.197836 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (21, 828)\n",
            "I0713 22:53:32.874997 140417550112640 basic_session_run_hooks.py:260] loss = 0.22839424, step = 222000 (67.048 sec)\n",
            "I0713 22:53:32.876482 140417550112640 tpu_estimator.py:2159] global_step/sec: 14.9149\n",
            "I0713 22:53:32.876706 140417550112640 tpu_estimator.py:2160] examples/sec: 954.551\n",
            "I0713 22:53:32.877985 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:53:32.878176 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:54:21.197853 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (22, 735)\n",
            "I0713 22:54:38.860515 140417550112640 basic_session_run_hooks.py:260] loss = 1.2476938, step = 223000 (65.985 sec)\n",
            "I0713 22:54:38.862080 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1548\n",
            "I0713 22:54:38.862271 140417550112640 tpu_estimator.py:2160] examples/sec: 969.908\n",
            "I0713 22:54:39.791571 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:54:39.792125 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:55:21.248862 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (23, 628)\n",
            "I0713 22:55:45.810656 140417550112640 basic_session_run_hooks.py:260] loss = 1.7929841, step = 224000 (66.950 sec)\n",
            "I0713 22:55:45.812512 140417550112640 tpu_estimator.py:2159] global_step/sec: 14.9364\n",
            "I0713 22:55:45.812736 140417550112640 tpu_estimator.py:2160] examples/sec: 955.933\n",
            "I0713 22:55:45.814176 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:55:45.814437 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:56:21.284768 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (24, 534)\n",
            "I0713 22:56:52.726658 140417550112640 basic_session_run_hooks.py:260] loss = 2.6349235, step = 225000 (66.916 sec)\n",
            "I0713 22:56:52.728458 140417550112640 tpu_estimator.py:2159] global_step/sec: 14.9441\n",
            "I0713 22:56:52.728847 140417550112640 tpu_estimator.py:2160] examples/sec: 956.423\n",
            "I0713 22:56:52.730449 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:56:52.730675 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:57:21.301683 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (25, 426)\n",
            "I0713 22:57:58.687548 140417550112640 basic_session_run_hooks.py:260] loss = 1.9538431, step = 226000 (65.961 sec)\n",
            "I0713 22:57:58.689020 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1606\n",
            "I0713 22:57:58.689210 140417550112640 tpu_estimator.py:2160] examples/sec: 970.277\n",
            "I0713 22:57:58.690393 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:57:58.690564 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:58:21.316967 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (26, 333)\n",
            "I0713 22:59:04.710799 140417550112640 basic_session_run_hooks.py:260] loss = 1.6330531, step = 227000 (66.023 sec)\n",
            "I0713 22:59:04.712616 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1461\n",
            "I0713 22:59:04.712813 140417550112640 tpu_estimator.py:2160] examples/sec: 969.351\n",
            "I0713 22:59:05.713880 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 22:59:05.714697 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 22:59:21.319283 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (27, 223)\n",
            "I0713 23:00:11.804210 140417550112640 basic_session_run_hooks.py:260] loss = 1.3582339, step = 228000 (67.093 sec)\n",
            "I0713 23:00:11.806244 140417550112640 tpu_estimator.py:2159] global_step/sec: 14.9045\n",
            "I0713 23:00:11.806452 140417550112640 tpu_estimator.py:2160] examples/sec: 953.89\n",
            "I0713 23:00:11.808472 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:00:11.808714 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:00:21.338965 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (28, 129)\n",
            "I0713 23:01:17.754045 140417550112640 basic_session_run_hooks.py:260] loss = 0.74304634, step = 229000 (65.950 sec)\n",
            "I0713 23:01:17.756010 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1631\n",
            "I0713 23:01:17.756470 140417550112640 tpu_estimator.py:2160] examples/sec: 970.438\n",
            "I0713 23:01:18.632672 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:01:18.633533 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:01:21.345760 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (29, 23)\n",
            "I0713 23:02:21.347091 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (29, 961)\n",
            "I0713 23:02:24.536943 140417550112640 basic_session_run_hooks.py:606] Saving checkpoints for 230000 into gs://gurebert/gureBERT/wordpiece/model/model.ckpt.\n",
            "I0713 23:02:51.265088 140417550112640 basic_session_run_hooks.py:260] loss = 1.1438593, step = 230000 (93.511 sec)\n",
            "I0713 23:02:51.267148 140417550112640 tpu_estimator.py:2159] global_step/sec: 10.6939\n",
            "I0713 23:02:51.267402 140417550112640 tpu_estimator.py:2160] examples/sec: 684.41\n",
            "I0713 23:02:51.269065 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:02:51.269377 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:03:21.395039 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (30, 451)\n",
            "I0713 23:03:58.235211 140417550112640 basic_session_run_hooks.py:260] loss = 1.2682352, step = 231000 (66.970 sec)\n",
            "I0713 23:03:58.237249 140417550112640 tpu_estimator.py:2159] global_step/sec: 14.932\n",
            "I0713 23:03:58.237640 140417550112640 tpu_estimator.py:2160] examples/sec: 955.65\n",
            "I0713 23:03:58.239296 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:03:58.239494 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:04:21.425872 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (31, 341)\n",
            "I0713 23:05:04.315245 140417550112640 basic_session_run_hooks.py:260] loss = 1.6408346, step = 232000 (66.080 sec)\n",
            "I0713 23:05:04.316936 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1332\n",
            "I0713 23:05:04.317151 140417550112640 tpu_estimator.py:2160] examples/sec: 968.527\n",
            "I0713 23:05:04.318480 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:05:04.318727 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:05:21.452068 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (32, 247)\n",
            "I0713 23:06:10.385185 140417550112640 basic_session_run_hooks.py:260] loss = 3.2189353, step = 233000 (66.070 sec)\n",
            "I0713 23:06:10.387267 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1354\n",
            "I0713 23:06:10.387520 140417550112640 tpu_estimator.py:2160] examples/sec: 968.666\n",
            "I0713 23:06:11.320570 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:06:11.320942 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:06:21.462158 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (33, 138)\n",
            "I0713 23:07:17.372255 140417550112640 basic_session_run_hooks.py:260] loss = 1.3319443, step = 234000 (66.987 sec)\n",
            "I0713 23:07:17.374134 140417550112640 tpu_estimator.py:2159] global_step/sec: 14.9283\n",
            "I0713 23:07:17.374347 140417550112640 tpu_estimator.py:2160] examples/sec: 955.41\n",
            "I0713 23:07:17.375604 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:07:17.375864 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:07:21.486183 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (34, 44)\n",
            "I0713 23:08:21.499975 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (34, 982)\n",
            "I0713 23:08:23.372071 140417550112640 basic_session_run_hooks.py:260] loss = 1.555983, step = 235000 (66.000 sec)\n",
            "I0713 23:08:23.374204 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1515\n",
            "I0713 23:08:23.374495 140417550112640 tpu_estimator.py:2160] examples/sec: 969.697\n",
            "I0713 23:08:24.372439 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:08:24.373270 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:09:21.556046 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (35, 873)\n",
            "I0713 23:09:30.376457 140417550112640 basic_session_run_hooks.py:260] loss = 2.3093917, step = 236000 (67.004 sec)\n",
            "I0713 23:09:30.378038 140417550112640 tpu_estimator.py:2159] global_step/sec: 14.9245\n",
            "I0713 23:09:30.378250 140417550112640 tpu_estimator.py:2160] examples/sec: 955.168\n",
            "I0713 23:09:30.379742 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:09:30.380021 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:10:21.609090 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (36, 780)\n",
            "I0713 23:10:37.355703 140417550112640 basic_session_run_hooks.py:260] loss = 1.5604916, step = 237000 (66.979 sec)\n",
            "I0713 23:10:37.357452 140417550112640 tpu_estimator.py:2159] global_step/sec: 14.93\n",
            "I0713 23:10:37.358133 140417550112640 tpu_estimator.py:2160] examples/sec: 955.518\n",
            "I0713 23:10:37.359870 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:10:37.360115 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:11:21.619484 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (37, 672)\n",
            "I0713 23:11:43.336919 140417550112640 basic_session_run_hooks.py:260] loss = 1.5737402, step = 238000 (65.981 sec)\n",
            "I0713 23:11:43.338685 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1558\n",
            "I0713 23:11:43.338932 140417550112640 tpu_estimator.py:2160] examples/sec: 969.972\n",
            "I0713 23:11:43.340715 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:11:43.340975 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:12:21.620549 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (38, 578)\n",
            "I0713 23:12:49.350722 140417550112640 basic_session_run_hooks.py:260] loss = 1.1162081, step = 239000 (66.014 sec)\n",
            "I0713 23:12:49.352396 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1484\n",
            "I0713 23:12:49.352607 140417550112640 tpu_estimator.py:2160] examples/sec: 969.495\n",
            "I0713 23:12:50.272897 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:12:50.273456 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:13:21.660653 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (39, 470)\n",
            "I0713 23:13:56.298989 140417550112640 basic_session_run_hooks.py:606] Saving checkpoints for 240000 into gs://gurebert/gureBERT/wordpiece/model/model.ckpt.\n",
            "I0713 23:14:21.859693 140417550112640 basic_session_run_hooks.py:260] loss = 2.1730852, step = 240000 (92.509 sec)\n",
            "I0713 23:14:21.861325 140417550112640 tpu_estimator.py:2159] global_step/sec: 10.8098\n",
            "I0713 23:14:21.861546 140417550112640 tpu_estimator.py:2160] examples/sec: 691.825\n",
            "I0713 23:14:21.863237 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:14:21.863443 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:14:23.172109 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (40, 0)\n",
            "I0713 23:15:23.174911 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (40, 938)\n",
            "I0713 23:15:27.804829 140417550112640 basic_session_run_hooks.py:260] loss = 1.3844596, step = 241000 (65.945 sec)\n",
            "I0713 23:15:27.806453 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1641\n",
            "I0713 23:15:27.806669 140417550112640 tpu_estimator.py:2160] examples/sec: 970.504\n",
            "I0713 23:15:28.690301 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:15:28.690958 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:16:23.179082 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (41, 831)\n",
            "I0713 23:16:34.695687 140417550112640 basic_session_run_hooks.py:260] loss = 0.7983379, step = 242000 (66.891 sec)\n",
            "I0713 23:16:34.697164 140417550112640 tpu_estimator.py:2159] global_step/sec: 14.9498\n",
            "I0713 23:16:34.697409 140417550112640 tpu_estimator.py:2160] examples/sec: 956.784\n",
            "I0713 23:16:34.699081 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:16:34.699322 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:17:23.218021 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (42, 737)\n",
            "I0713 23:17:41.610322 140417550112640 basic_session_run_hooks.py:260] loss = 1.8749676, step = 243000 (66.915 sec)\n",
            "I0713 23:17:41.612033 140417550112640 tpu_estimator.py:2159] global_step/sec: 14.9444\n",
            "I0713 23:17:41.612233 140417550112640 tpu_estimator.py:2160] examples/sec: 956.439\n",
            "I0713 23:17:41.613482 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:17:41.613670 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:18:23.268909 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (43, 631)\n",
            "I0713 23:18:47.587042 140417550112640 basic_session_run_hooks.py:260] loss = 1.0837766, step = 244000 (65.977 sec)\n",
            "I0713 23:18:47.589060 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1568\n",
            "I0713 23:18:47.589355 140417550112640 tpu_estimator.py:2160] examples/sec: 970.035\n",
            "I0713 23:18:47.591102 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:18:47.591476 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:19:23.299426 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (44, 537)\n",
            "I0713 23:19:53.666673 140417550112640 basic_session_run_hooks.py:260] loss = 1.7880898, step = 245000 (66.080 sec)\n",
            "I0713 23:19:53.668653 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1333\n",
            "I0713 23:19:53.668908 140417550112640 tpu_estimator.py:2160] examples/sec: 968.53\n",
            "I0713 23:19:54.587562 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:19:54.588208 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:20:23.304447 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (45, 428)\n",
            "I0713 23:21:00.663489 140417550112640 basic_session_run_hooks.py:260] loss = 0.74924064, step = 246000 (66.997 sec)\n",
            "I0713 23:21:00.665076 140417550112640 tpu_estimator.py:2159] global_step/sec: 14.9261\n",
            "I0713 23:21:00.665493 140417550112640 tpu_estimator.py:2160] examples/sec: 955.273\n",
            "I0713 23:21:00.666594 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:21:00.666772 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:21:23.325252 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (46, 335)\n",
            "I0713 23:22:06.595830 140417550112640 basic_session_run_hooks.py:260] loss = 2.3442695, step = 247000 (65.932 sec)\n",
            "I0713 23:22:06.597474 140417550112640 tpu_estimator.py:2159] global_step/sec: 15.1671\n",
            "I0713 23:22:07.518631 140417550112640 tpu_estimator.py:2160] examples/sec: 970.692\n",
            "I0713 23:22:07.521314 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:22:07.521717 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:22:23.381153 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (47, 227)\n",
            "I0713 23:23:13.545078 140417550112640 basic_session_run_hooks.py:260] loss = 1.9162123, step = 248000 (66.949 sec)\n",
            "I0713 23:23:13.546945 140417550112640 tpu_estimator.py:2159] global_step/sec: 14.9366\n",
            "I0713 23:23:13.547159 140417550112640 tpu_estimator.py:2160] examples/sec: 955.945\n",
            "I0713 23:23:13.548633 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:23:13.548854 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:23:23.419207 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (48, 134)\n",
            "I0713 23:24:21.502909 140417550112640 basic_session_run_hooks.py:260] loss = 2.5535753, step = 249000 (67.958 sec)\n",
            "I0713 23:24:21.505060 140417550112640 tpu_estimator.py:2159] global_step/sec: 14.715\n",
            "I0713 23:24:21.505388 140417550112640 tpu_estimator.py:2160] examples/sec: 941.757\n",
            "I0713 23:24:21.507176 140417550112640 tpu_estimator.py:590] Enqueue next (1000) batch(es) of data to infeed.\n",
            "I0713 23:24:21.507457 140417550112640 tpu_estimator.py:594] Dequeue next (1000) batch(es) of data from outfeed.\n",
            "I0713 23:24:23.434517 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (49, 10)\n",
            "I0713 23:25:23.446701 140416363865856 tpu_estimator.py:275] Outfeed finished for iteration (49, 948)\n",
            "I0713 23:25:27.549682 140417550112640 basic_session_run_hooks.py:606] Saving checkpoints for 250000 into gs://gurebert/gureBERT/wordpiece/model/model.ckpt.\n",
            "I0713 23:25:54.880683 140417550112640 basic_session_run_hooks.py:260] loss = 1.7120332, step = 250000 (93.378 sec)\n",
            "I0713 23:25:54.882963 140417550112640 tpu_estimator.py:2159] global_step/sec: 10.7092\n",
            "I0713 23:25:54.883222 140417550112640 tpu_estimator.py:2160] examples/sec: 685.387\n",
            "I0713 23:25:55.872713 140417550112640 tpu_estimator.py:598] Stop infeed thread controller\n",
            "I0713 23:25:55.872985 140417550112640 tpu_estimator.py:430] Shutting down InfeedController thread.\n",
            "I0713 23:25:55.873187 140416392439552 tpu_estimator.py:425] InfeedController received shutdown signal, stopping.\n",
            "I0713 23:25:55.873307 140416392439552 tpu_estimator.py:530] Infeed thread finished, shutting down.\n",
            "I0713 23:25:55.873549 140417550112640 error_handling.py:96] infeed marked as finished\n",
            "I0713 23:25:55.873704 140417550112640 tpu_estimator.py:602] Stop output thread controller\n",
            "I0713 23:25:55.873785 140417550112640 tpu_estimator.py:430] Shutting down OutfeedController thread.\n",
            "I0713 23:25:55.873978 140416363865856 tpu_estimator.py:425] OutfeedController received shutdown signal, stopping.\n",
            "I0713 23:25:55.874068 140416363865856 tpu_estimator.py:541] Outfeed thread finished, shutting down.\n",
            "I0713 23:25:55.874191 140417550112640 error_handling.py:96] outfeed marked as finished\n",
            "I0713 23:25:55.874297 140417550112640 tpu_estimator.py:606] Shutdown TPU system.\n",
            "I0713 23:25:57.744201 140417550112640 estimator.py:368] Loss for final step: 1.7120332.\n",
            "I0713 23:25:57.745436 140417550112640 error_handling.py:96] training_loop marked as finished\n",
            "I0713 23:25:57.745630 140417550112640 run_pretraining.py:469] ***** Running evaluation *****\n",
            "I0713 23:25:57.745742 140417550112640 run_pretraining.py:470]   Batch size = 8\n",
            "I0713 23:25:58.601117 140417550112640 estimator.py:1145] Calling model_fn.\n",
            "I0713 23:25:58.705183 140417550112640 run_pretraining.py:117] *** Features ***\n",
            "I0713 23:25:58.705520 140417550112640 run_pretraining.py:119]   name = input_ids, shape = (1, 128)\n",
            "I0713 23:25:58.705826 140417550112640 run_pretraining.py:119]   name = input_mask, shape = (1, 128)\n",
            "I0713 23:25:58.705971 140417550112640 run_pretraining.py:119]   name = masked_lm_ids, shape = (1, 19)\n",
            "I0713 23:25:58.706065 140417550112640 run_pretraining.py:119]   name = masked_lm_positions, shape = (1, 19)\n",
            "I0713 23:25:58.706204 140417550112640 run_pretraining.py:119]   name = masked_lm_weights, shape = (1, 19)\n",
            "I0713 23:25:58.706291 140417550112640 run_pretraining.py:119]   name = next_sentence_labels, shape = (1, 1)\n",
            "I0713 23:25:58.706379 140417550112640 run_pretraining.py:119]   name = segment_ids, shape = (1, 128)\n",
            "I0713 23:26:02.926305 140417550112640 run_pretraining.py:167] **** Trainable Variables ****\n",
            "I0713 23:26:02.926631 140417550112640 run_pretraining.py:173]   name = bert/embeddings/word_embeddings:0, shape = (32000, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.926792 140417550112640 run_pretraining.py:173]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.926886 140417550112640 run_pretraining.py:173]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.926975 140417550112640 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.927060 140417550112640 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.927143 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.927225 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.927302 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.927382 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.927457 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.927537 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.927631 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.927712 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.927795 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.927868 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.927942 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.928020 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.928094 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.928171 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.928247 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.928321 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.928395 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.928473 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.928547 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.928641 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.928716 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.928801 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.928876 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.928955 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.929029 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.929105 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.929179 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.929258 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.929334 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.929412 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.929486 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.929560 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.929651 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.929737 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.929811 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.929889 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.929962 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.930041 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.930115 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.930191 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.930265 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.930339 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.930412 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.930488 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.930562 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.930656 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.930737 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.930813 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.930902 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.930981 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.931064 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.931143 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.931217 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.931297 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.931372 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.931449 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.931523 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.931612 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.931690 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.931775 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.931851 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.931930 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.932007 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.932081 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.932155 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.932234 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.932308 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.932386 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.932462 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.932541 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.932630 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.932710 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.932792 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.932867 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.932942 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.933019 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.933093 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.933169 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.933242 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.933316 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.933391 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.933467 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.933541 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.933634 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.933709 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.933795 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.933870 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.933950 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.934025 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.934099 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.934174 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.934254 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.934333 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.934411 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.934485 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.934558 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.934648 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.934734 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.934809 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.934886 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.934960 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.935039 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.935113 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.935189 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.935269 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.935348 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.935421 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.935500 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.935589 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.935676 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.935762 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.935837 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.935911 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.935991 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.975448 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.975793 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.975966 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.976081 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.976194 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.976322 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.976435 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.976544 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.976670 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.976782 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.976888 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.976997 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.977101 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.977213 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.977334 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.977446 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.977553 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.977689 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.977799 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.977910 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.978013 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.978124 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.978240 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.978347 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.978452 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.978563 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.978699 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.978814 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.978920 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.979027 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.979133 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.979252 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.979361 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.979472 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.979603 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.979718 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.979828 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.979938 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.980039 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.980141 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.980282 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.980398 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.980502 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.980730 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.980864 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.980976 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.981084 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.981198 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.981321 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.981436 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.981554 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.981694 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.981807 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.981920 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.982022 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.982126 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.982245 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.982368 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.982475 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.982604 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.982716 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.982818 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.982920 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.983030 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.983134 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.983253 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.983361 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.983471 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.983574 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.983714 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.983824 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.983928 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.984030 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.984138 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.984254 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.984364 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.984469 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.984574 140417550112640 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.984706 140417550112640 run_pretraining.py:173]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.984818 140417550112640 run_pretraining.py:173]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.984925 140417550112640 run_pretraining.py:173]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.985035 140417550112640 run_pretraining.py:173]   name = cls/predictions/transform/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.985139 140417550112640 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.985254 140417550112640 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.985362 140417550112640 run_pretraining.py:173]   name = cls/predictions/output_bias:0, shape = (32000,), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.985466 140417550112640 run_pretraining.py:173]   name = cls/seq_relationship/output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "I0713 23:26:02.985574 140417550112640 run_pretraining.py:173]   name = cls/seq_relationship/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
            "W0713 23:26:05.641611 140417550112640 deprecation_wrapper.py:119] From bert/run_pretraining.py:198: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
            "\n",
            "W0713 23:26:05.659096 140417550112640 deprecation_wrapper.py:119] From bert/run_pretraining.py:202: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "I0713 23:26:06.718362 140417550112640 estimator.py:1147] Done calling model_fn.\n",
            "I0713 23:26:06.737710 140417550112640 evaluation.py:255] Starting evaluation at 2019-07-13T23:26:06Z\n",
            "I0713 23:26:06.737991 140417550112640 tpu_estimator.py:499] TPU job name worker\n",
            "I0713 23:26:07.370014 140417550112640 monitored_session.py:240] Graph was finalized.\n",
            "I0713 23:26:07.588264 140417550112640 saver.py:1280] Restoring parameters from gs://gurebert/gureBERT/wordpiece/model/model.ckpt-250000\n",
            "I0713 23:26:41.763711 140417550112640 session_manager.py:500] Running local_init_op.\n",
            "I0713 23:26:41.984994 140417550112640 session_manager.py:502] Done running local_init_op.\n",
            "I0713 23:26:42.503966 140417550112640 tpu_estimator.py:557] Init TPU system\n",
            "I0713 23:26:50.960073 140417550112640 tpu_estimator.py:566] Initialized TPU in 8 seconds\n",
            "I0713 23:26:50.961115 140416568350464 tpu_estimator.py:514] Starting infeed thread controller.\n",
            "I0713 23:26:50.961675 140416559957760 tpu_estimator.py:533] Starting outfeed thread controller.\n",
            "I0713 23:26:51.213203 140417550112640 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "I0713 23:26:51.423350 140417550112640 tpu_estimator.py:590] Enqueue next (100) batch(es) of data to infeed.\n",
            "I0713 23:26:51.423775 140417550112640 tpu_estimator.py:594] Dequeue next (100) batch(es) of data from outfeed.\n",
            "I0713 23:26:55.941613 140416559957760 tpu_estimator.py:275] Outfeed finished for iteration (0, 0)\n",
            "I0713 23:26:57.449304 140417550112640 evaluation.py:167] Evaluation [100/100]\n",
            "I0713 23:26:57.449711 140417550112640 tpu_estimator.py:598] Stop infeed thread controller\n",
            "I0713 23:26:57.449803 140417550112640 tpu_estimator.py:430] Shutting down InfeedController thread.\n",
            "I0713 23:26:57.449991 140416568350464 tpu_estimator.py:425] InfeedController received shutdown signal, stopping.\n",
            "I0713 23:26:57.450091 140416568350464 tpu_estimator.py:530] Infeed thread finished, shutting down.\n",
            "I0713 23:26:57.450235 140417550112640 error_handling.py:96] infeed marked as finished\n",
            "I0713 23:26:57.450371 140417550112640 tpu_estimator.py:602] Stop output thread controller\n",
            "I0713 23:26:57.450438 140417550112640 tpu_estimator.py:430] Shutting down OutfeedController thread.\n",
            "I0713 23:26:58.004692 140416559957760 tpu_estimator.py:425] OutfeedController received shutdown signal, stopping.\n",
            "I0713 23:26:58.004975 140416559957760 tpu_estimator.py:541] Outfeed thread finished, shutting down.\n",
            "I0713 23:26:58.005147 140417550112640 error_handling.py:96] outfeed marked as finished\n",
            "I0713 23:26:58.005307 140417550112640 tpu_estimator.py:606] Shutdown TPU system.\n",
            "I0713 23:26:58.701085 140417550112640 evaluation.py:275] Finished evaluation at 2019-07-13-23:26:58\n",
            "I0713 23:26:58.701418 140417550112640 estimator.py:2039] Saving dict for global step 250000: global_step = 250000, loss = 1.5279938, masked_lm_accuracy = 0.7164289, masked_lm_loss = 1.464413, next_sentence_accuracy = 0.9725, next_sentence_loss = 0.083929874\n",
            "I0713 23:27:02.265861 140417550112640 estimator.py:2099] Saving 'checkpoint_path' summary for global step 250000: gs://gurebert/gureBERT/wordpiece/model/model.ckpt-250000\n",
            "I0713 23:27:03.108373 140417550112640 error_handling.py:96] evaluation_loop marked as finished\n",
            "I0713 23:27:03.108805 140417550112640 run_pretraining.py:483] ***** Eval results *****\n",
            "I0713 23:27:03.108935 140417550112640 run_pretraining.py:485]   global_step = 250000\n",
            "I0713 23:27:03.109235 140417550112640 run_pretraining.py:485]   loss = 1.5279938\n",
            "I0713 23:27:03.109360 140417550112640 run_pretraining.py:485]   masked_lm_accuracy = 0.7164289\n",
            "I0713 23:27:03.109444 140417550112640 run_pretraining.py:485]   masked_lm_loss = 1.464413\n",
            "I0713 23:27:03.109521 140417550112640 run_pretraining.py:485]   next_sentence_accuracy = 0.9725\n",
            "I0713 23:27:03.109617 140417550112640 run_pretraining.py:485]   next_sentence_loss = 0.083929874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1c7_R5EdYFv",
        "colab_type": "text"
      },
      "source": [
        "# gureBERT EN-EU Sorkuntza\n",
        "\n",
        "Irakurri:\n",
        "- https://github.com/google-research/bert/blob/master/multilingual.md#data-source-and-sampling:\n",
        "\n",
        "> To balance these two factors, we performed exponentially smoothed weighting of the data during pre-training data creation (and WordPiece vocab creation). In other words, let's say that the probability of a language is P(L), e.g., P(English) = 0.21 means that after concatenating all of the Wikipedias together, 21% of our data is English. We exponentiate each probability by some factor S and then re-normalize, and sample from that distribution. In our case we use S=0.7. So, high-resource languages like English will be under-sampled, and low-resource languages like Icelandic will be over-sampled. E.g., in the original distribution English would be sampled 1000x more than Icelandic, but after smoothing it's only sampled 100x more.\n",
        "\n",
        "- https://github.com/google-research/bert/blob/master/multilingual.md#tokenization:\n",
        "\n",
        "> For tokenization, we use a 110k shared WordPiece vocabulary. The word counts are weighted the same way as the data, so low-resource languages are upweighted by some factor. We intentionally do not use any marker to denote the input language (so that zero-shot training can work).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUcKt7Ehn6lV",
        "colab_type": "text"
      },
      "source": [
        "# gureBERT (japanese) erabiliz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqPX8zgt6lAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################################################################\n",
        "# gureBERT japanese\n",
        "\n",
        "!cd /content/\n",
        "\n",
        "!git clone --recursive https://github.com/zmwebdev/bert-japanese\n",
        "%cd bert-japanese\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d68MKTOjQxVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrhObi5n8xYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 src/data-download-and-extract.py\n",
        "!bash src/file-preprocessing.sh\n",
        "\n",
        "#!gsutil cp -r gs://gurebert/gureBERT/data/wiki/AA/wiki_00 data/wiki/AA/wiki_00\n",
        "\n",
        "# Oharra: esaldiak lerro bakarrean jarri behar dira\n",
        "#!cat data/wiki/AA/wiki_00"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m0o4LUCJ8ci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wiki-eu.vocab eta wiki-eu.model sortzen ditu\n",
        "\n",
        "!pip install sentencepiece\n",
        "!python3 src/train-sentencepiece.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJFc3jAkOyHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil cp -r data/ gs://gurebert/gureBERT/\n",
        "!gsutil cp -r model/ gs://gurebert/gureBERT/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_qxPQAgP1sA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir model\n",
        "!gsutil cp gs://gurebert/gureBERT/model/wiki-eu.vocab model\n",
        "!gsutil cp gs://gurebert/gureBERT/model/wiki-eu.model model\n",
        "!head -n 50 model/wiki-eu.vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl457PDf8r-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/zmwebdev/bert-japanese/blob/master/notebook/check-trained-tokenizer.ipynb\n",
        "!pip install sentencepiece\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"src\")\n",
        "\n",
        "import tokenization_sentencepiece as tokenization\n",
        "\n",
        "text1 = \"Nere kotxea aitonaren etxe alboan dago\"\n",
        "text2 = \"Gorria da gure etxearen inguruan dagoen lorearen kolorea\"\n",
        "\n",
        "tokenizer = tokenization.FullTokenizer(\n",
        "    model_file=\"model/wiki-eu.model\",\n",
        "    vocab_file=\"model/wiki-eu.vocab\",\n",
        "    do_lower_case=True)\n",
        "\n",
        "tokenizer.tokenize(text1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ExyRkNqGpvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.tokenize(text2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u9yUjU0HHwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#do_lower_case=False jarrita tokenizazioa okerragoa da\n",
        "tokenizer = tokenization.FullTokenizer(\n",
        "    model_file=\"model/wiki-eu.model\",\n",
        "    vocab_file=\"model/wiki-eu.vocab\",\n",
        "    do_lower_case=False)\n",
        "\n",
        "tokenizer.tokenize(text1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZMfqyxoHZnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.tokenize(text2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wosrOAdz2gQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert to WordPiece (kodean errorea dago). begiratu https://github.com/kwonmha/bert-vocab-builder/pull/4#issue-291306156\n",
        "\n",
        "!git clone https://github.com/kwonmha/bert-vocab-builder.git\n",
        "\n",
        "!python bert-vocab-builder/subword_builder.py \\\n",
        "--corpus_filepattern model/wiki-eu.vocab \\\n",
        "--output_filename model/wiki-eu-wordpiece.vocab\n",
        "#--min_count {minimum_subtoken_counts}\n",
        "\n",
        "# https://github.com/kwonmha/bert-vocab-builder/pull/4#issue-291306156"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBDprGbXRt4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating data for pretraining\n",
        "#Create .tfrecord files for pretraining. For longer sentence data, replace the value of max_seq_length with 512.\n",
        "!cat creating_data_for_pretraining.sh\n",
        "!bash creating_data_for_pretraining.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlBYBR1_G9Zt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# copy to gs\n",
        "!gsutil cp -r data gs://gurebert/gureBERT\n",
        "!gsutil cp -r model gs://gurebert/gureBERT\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29sDsZvBgFLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pre-Training\n",
        "# https://github.com/yoheikikuta/bert-japanese/blob/master/notebook/pretraining.ipynb\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "#Check TPU devices\n",
        "\n",
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU.\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AzYwFXw8iJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DATA_GCS = 'gs://gurebert/gureBERT/data/wiki'\n",
        "TARGET_DIRS = [\n",
        "  'AA',\n",
        "  'AB',\n",
        "  'AC'\n",
        "]\n",
        "\n",
        "MAX_SEQ_LEN = 128\n",
        "#MAX_SEQ_LEN = 512\n",
        "\n",
        "\n",
        "INPUT_FILE = ','.join( [ '{}/{}/all-maxseq{}.tfrecord'.format(INPUT_DATA_GCS, elem, MAX_SEQ_LEN) for elem in TARGET_DIRS] )\n",
        "\n",
        "OUTPUT_GCS = 'gs://gurebert/gureBERT/model'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRRjRvl19NDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding whole word masking aldaketa egin dute BERT-en. update egin behar da!!!\n",
        "# Begiratu https://github.com/google-research/bert/commit/0fce551b55caabcfba52c61e18f34b541aef186a\n",
        "\n",
        "!python src/run_pretraining.py \\\n",
        "  --input_file={INPUT_FILE} \\\n",
        "  --output_dir={OUTPUT_GCS} \\\n",
        "  --use_tpu=True \\\n",
        "  --tpu_name={TPU_ADDRESS} \\\n",
        "  --num_tpu_cores=8 \\\n",
        "  --do_train=True \\\n",
        "  --do_eval=True \\\n",
        "  --train_batch_size=64 \\\n",
        "  --max_seq_length={MAX_SEQ_LEN} \\\n",
        "  --max_predictions_per_seq=20 \\\n",
        "  --num_train_steps=1400000 \\\n",
        "  --num_warmup_steps=10000 \\\n",
        "  --save_checkpoints_steps=10000 \\\n",
        "  --learning_rate=1e-4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MGl6QPM4B9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########################################\n",
        "##########################################\n",
        "\n",
        "# BERT-ekin konpatiblea den vocab sortzeko prozedura. wordpiece _ -> ##. \n",
        "# Honen abantaila BERT kodearen aldaketak eta run_squad.py, ... ezer aldatu gabe ibiliko dela da.\n",
        "# berez ez da wordpiece, sentencepiece baizik baina sintaktikoki konpatiblea\n",
        "# ikusi: https://colab.research.google.com/drive/1-uLyGTnz2K4gx3su6Qc00in9QCa4b5Kh#scrollTo=9S4CiOh3RzFW\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "psBPQwy2y8UO",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "def read_sentencepiece_vocab(filepath):\n",
        "  voc = []\n",
        "  with open(filepath, encoding='utf-8') as fi:\n",
        "    for line in fi:\n",
        "      voc.append(line.split(\"\\t\")[0])\n",
        "  # skip the first <unk> token\n",
        "  voc = voc[1:]\n",
        "  return voc\n",
        "\n",
        "snt_vocab = read_sentencepiece_vocab(\"{}.vocab\".format('model/wiki-eu'))\n",
        "print(\"Learnt vocab size: {}\".format(len(snt_vocab)))\n",
        "print(\"Sample tokens: {}\".format(random.sample(snt_vocab, 10)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mia3KTjty8Vp",
        "colab": {}
      },
      "source": [
        "def parse_sentencepiece_token(token):\n",
        "    if token.startswith(\"▁\"):\n",
        "        return token[1:]\n",
        "    else:\n",
        "        return \"##\" + token"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9LbsNuney8V-",
        "colab": {}
      },
      "source": [
        "bert_vocab = list(map(parse_sentencepiece_token, snt_vocab))\n",
        "\n",
        "ctrl_symbols = [\"[PAD]\",\"[UNK]\",\"[CLS]\",\"[SEP]\",\"[MASK]\"]\n",
        "bert_vocab = ctrl_symbols + bert_vocab\n",
        "\n",
        "bert_vocab += [\"[UNUSED_{}]\".format(i) for i in range(32000 - len(bert_vocab))]\n",
        "print(len(bert_vocab))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jxBd_J30y8WV",
        "colab": {}
      },
      "source": [
        "VOC_FNAME = \"vocab.txt\" #@param {type:\"string\"}\n",
        "\n",
        "with open(VOC_FNAME, \"w\") as fo:\n",
        "  for token in bert_vocab:\n",
        "    fo.write(token+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OgRdyQpEy8Wh",
        "colab": {}
      },
      "source": [
        "from bert import tokenization\n",
        "\n",
        "bert_tokenizer = tokenization.FullTokenizer(VOC_FNAME)\n",
        "bert_tokenizer.tokenize(\"Nere kotxea aitonaren etxe alboan dago\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dAZRoG-Jy8W1",
        "colab": {}
      },
      "source": [
        "#!gsutil cp -r gs://gurebert/gureBERT/data/wiki/AA/wiki_00 wiki_00\n",
        "# ez du wiki-eu.model behar, vocab.txt-ekin nahikoa da\n",
        "\n",
        "!python bert/create_pretraining_data.py \\\n",
        "  --input_file=wiki_00 \\\n",
        "  --output_file=/tmp/tf_examples.tfrecord \\\n",
        "  --vocab_file=vocab.txt \\\n",
        "  --do_lower_case=True \\\n",
        "  --max_seq_length=128 \\\n",
        "  --max_predictions_per_seq=20 \\\n",
        "  --masked_lm_prob=0.15 \\\n",
        "  --random_seed=12345 \\\n",
        "  --dupe_factor=5\n",
        "\n",
        "#############################################################\n",
        "#############################################################"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}